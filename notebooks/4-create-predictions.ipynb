{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras as kr\n",
    "import pathlib as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blanc/Documents/GitHub/titanic-ml-tfp/data/raw/train.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_model_path = pl.Path(\"../models/inference_model.keras\")\n",
    "training_model_path = pl.Path(\"../models/training_model.keras\")\n",
    "titanic_data_test_path = pl.Path(\"../data/raw/train.csv\")\n",
    "\n",
    "inference_model_path.resolve()\n",
    "training_model_path.resolve()\n",
    "titanic_data_test_path.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se deben predecir un total de 891 casos\n"
     ]
    }
   ],
   "source": [
    "titanic_data_test = pd.read_csv(filepath_or_buffer=titanic_data_test_path)\n",
    "titanic_data_test.loc[titanic_data_test[\"Embarked\"].isna(), \"Embarked\"] = \"D\"\n",
    "titanic_data_test = titanic_data_test.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"Pclass\",\n",
    "        \"Sex\",\n",
    "        \"Age\",\n",
    "        \"SibSp\",\n",
    "        \"Parch\",\n",
    "        \"Fare\",\n",
    "        \"Embarked\",\n",
    "    ],\n",
    "]\n",
    "print(\"Se deben predecir un total de {} casos\".format(len(titanic_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se deben predecir un total de 1 casos\n"
     ]
    }
   ],
   "source": [
    "# input_dict = {name: tf.convert_to_tensor(value) for name, value in sample.items()}\n",
    "titanic_dataset = tf.data.Dataset.from_tensors(tensors=dict(titanic_data_test))\n",
    "\n",
    "print(\n",
    "    \"Se deben predecir un total de {} casos\".format(\n",
    "        len(titanic_dataset),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Pclass': <tf.Tensor: shape=(891,), dtype=int64, numpy=\n",
       "  array([3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2,\n",
       "         3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3, 1, 1, 3, 1, 3,\n",
       "         2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3,\n",
       "         1, 3, 3, 3, 1, 3, 3, 3, 1, 1, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3,\n",
       "         1, 3, 3, 3, 3, 3, 3, 2, 1, 3, 2, 3, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 2, 2, 2, 1, 1, 3, 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 1, 3, 3,\n",
       "         3, 1, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3, 3, 1, 3,\n",
       "         3, 1, 2, 3, 3, 2, 3, 2, 3, 1, 3, 1, 3, 3, 2, 2, 3, 2, 1, 1, 3, 3,\n",
       "         3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 2, 3, 1, 3, 2, 1, 2,\n",
       "         3, 2, 3, 3, 1, 3, 2, 3, 2, 3, 1, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3,\n",
       "         2, 3, 3, 1, 3, 2, 1, 2, 3, 3, 1, 3, 3, 3, 1, 1, 1, 2, 3, 3, 1, 1,\n",
       "         3, 2, 3, 3, 1, 1, 1, 3, 2, 1, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3,\n",
       "         3, 3, 2, 3, 1, 1, 2, 3, 3, 1, 3, 1, 1, 1, 3, 3, 3, 2, 3, 1, 1, 1,\n",
       "         2, 1, 1, 1, 2, 3, 2, 3, 2, 2, 1, 1, 3, 3, 2, 2, 3, 1, 3, 2, 3, 1,\n",
       "         3, 1, 1, 3, 1, 3, 1, 1, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1,\n",
       "         3, 3, 3, 3, 1, 2, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 1, 1, 3, 3, 1,\n",
       "         3, 1, 3, 1, 3, 3, 1, 3, 3, 1, 3, 2, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3,\n",
       "         3, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 2, 2,\n",
       "         2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 1, 3, 2, 3, 1, 1, 3, 2, 1, 2,\n",
       "         2, 3, 3, 2, 3, 1, 2, 1, 3, 1, 2, 3, 1, 1, 3, 3, 1, 1, 2, 3, 1, 3,\n",
       "         1, 2, 3, 3, 2, 1, 3, 3, 3, 3, 2, 2, 3, 1, 2, 3, 3, 3, 3, 2, 3, 3,\n",
       "         1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1,\n",
       "         2, 1, 3, 3, 3, 3, 1, 1, 3, 1, 2, 3, 2, 3, 1, 3, 3, 1, 3, 3, 2, 1,\n",
       "         3, 2, 2, 3, 3, 3, 3, 2, 1, 1, 3, 1, 1, 3, 3, 2, 1, 1, 2, 2, 3, 2,\n",
       "         1, 2, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 1,\n",
       "         1, 3, 3, 3, 2, 1, 3, 3, 2, 1, 2, 1, 3, 1, 2, 1, 3, 3, 3, 1, 3, 3,\n",
       "         2, 3, 2, 3, 3, 1, 2, 3, 1, 3, 1, 3, 3, 1, 2, 1, 3, 3, 3, 3, 3, 2,\n",
       "         3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 2, 1, 3, 3, 1, 3, 1, 1, 3, 2, 3, 2,\n",
       "         3, 3, 3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 1,\n",
       "         1, 3, 1, 3, 3, 2, 2, 3, 3, 1, 2, 1, 2, 2, 2, 3, 3, 3, 3, 1, 3, 1,\n",
       "         3, 3, 2, 2, 3, 3, 3, 1, 1, 3, 3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 3, 3,\n",
       "         3, 2, 2, 1, 1, 3, 1, 1, 1, 3, 2, 3, 1, 2, 3, 3, 2, 3, 2, 2, 1, 3,\n",
       "         2, 3, 2, 3, 1, 3, 2, 2, 2, 3, 3, 1, 3, 3, 1, 1, 1, 3, 3, 1, 3, 2,\n",
       "         1, 3, 2, 3, 3, 3, 2, 2, 3, 2, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3,\n",
       "         3, 3, 2, 3, 2, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 2,\n",
       "         3, 1, 3, 2, 1, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1, 3, 2, 1, 3, 3, 2, 3,\n",
       "         3, 1, 3, 2, 3, 3, 1, 3, 1, 3, 3, 3, 3, 2, 3, 1, 3, 2, 3, 3, 3, 1,\n",
       "         3, 3, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 1, 2, 3, 1, 1,\n",
       "         3, 3, 3, 2, 1, 3, 2, 2, 2, 1, 3, 3, 3, 1, 1, 3, 2, 3, 3, 3, 3, 1,\n",
       "         2, 3, 3, 2, 3, 3, 2, 1, 3, 1, 3], dtype=int64)>,\n",
       "  'Sex': <tf.Tensor: shape=(891,), dtype=string, numpy=\n",
       "  array([b'male', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'female', b'female',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'female',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'female', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'female', b'female',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'female', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'female', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'female', b'female', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'male', b'male'], dtype=object)>,\n",
       "  'Age': <tf.Tensor: shape=(891,), dtype=float64, numpy=\n",
       "  array([22.  , 38.  , 26.  , 35.  , 35.  ,   nan, 54.  ,  2.  , 27.  ,\n",
       "         14.  ,  4.  , 58.  , 20.  , 39.  , 14.  , 55.  ,  2.  ,   nan,\n",
       "         31.  ,   nan, 35.  , 34.  , 15.  , 28.  ,  8.  , 38.  ,   nan,\n",
       "         19.  ,   nan,   nan, 40.  ,   nan,   nan, 66.  , 28.  , 42.  ,\n",
       "           nan, 21.  , 18.  , 14.  , 40.  , 27.  ,   nan,  3.  , 19.  ,\n",
       "           nan,   nan,   nan,   nan, 18.  ,  7.  , 21.  , 49.  , 29.  ,\n",
       "         65.  ,   nan, 21.  , 28.5 ,  5.  , 11.  , 22.  , 38.  , 45.  ,\n",
       "          4.  ,   nan,   nan, 29.  , 19.  , 17.  , 26.  , 32.  , 16.  ,\n",
       "         21.  , 26.  , 32.  , 25.  ,   nan,   nan,  0.83, 30.  , 22.  ,\n",
       "         29.  ,   nan, 28.  , 17.  , 33.  , 16.  ,   nan, 23.  , 24.  ,\n",
       "         29.  , 20.  , 46.  , 26.  , 59.  ,   nan, 71.  , 23.  , 34.  ,\n",
       "         34.  , 28.  ,   nan, 21.  , 33.  , 37.  , 28.  , 21.  ,   nan,\n",
       "         38.  ,   nan, 47.  , 14.5 , 22.  , 20.  , 17.  , 21.  , 70.5 ,\n",
       "         29.  , 24.  ,  2.  , 21.  ,   nan, 32.5 , 32.5 , 54.  , 12.  ,\n",
       "           nan, 24.  ,   nan, 45.  , 33.  , 20.  , 47.  , 29.  , 25.  ,\n",
       "         23.  , 19.  , 37.  , 16.  , 24.  ,   nan, 22.  , 24.  , 19.  ,\n",
       "         18.  , 19.  , 27.  ,  9.  , 36.5 , 42.  , 51.  , 22.  , 55.5 ,\n",
       "         40.5 ,   nan, 51.  , 16.  , 30.  ,   nan,   nan, 44.  , 40.  ,\n",
       "         26.  , 17.  ,  1.  ,  9.  ,   nan, 45.  ,   nan, 28.  , 61.  ,\n",
       "          4.  ,  1.  , 21.  , 56.  , 18.  ,   nan, 50.  , 30.  , 36.  ,\n",
       "           nan,   nan,  9.  ,  1.  ,  4.  ,   nan,   nan, 45.  , 40.  ,\n",
       "         36.  , 32.  , 19.  , 19.  ,  3.  , 44.  , 58.  ,   nan, 42.  ,\n",
       "           nan, 24.  , 28.  ,   nan, 34.  , 45.5 , 18.  ,  2.  , 32.  ,\n",
       "         26.  , 16.  , 40.  , 24.  , 35.  , 22.  , 30.  ,   nan, 31.  ,\n",
       "         27.  , 42.  , 32.  , 30.  , 16.  , 27.  , 51.  ,   nan, 38.  ,\n",
       "         22.  , 19.  , 20.5 , 18.  ,   nan, 35.  , 29.  , 59.  ,  5.  ,\n",
       "         24.  ,   nan, 44.  ,  8.  , 19.  , 33.  ,   nan,   nan, 29.  ,\n",
       "         22.  , 30.  , 44.  , 25.  , 24.  , 37.  , 54.  ,   nan, 29.  ,\n",
       "         62.  , 30.  , 41.  , 29.  ,   nan, 30.  , 35.  , 50.  ,   nan,\n",
       "          3.  , 52.  , 40.  ,   nan, 36.  , 16.  , 25.  , 58.  , 35.  ,\n",
       "           nan, 25.  , 41.  , 37.  ,   nan, 63.  , 45.  ,   nan,  7.  ,\n",
       "         35.  , 65.  , 28.  , 16.  , 19.  ,   nan, 33.  , 30.  , 22.  ,\n",
       "         42.  , 22.  , 26.  , 19.  , 36.  , 24.  , 24.  ,   nan, 23.5 ,\n",
       "          2.  ,   nan, 50.  ,   nan,   nan, 19.  ,   nan,   nan,  0.92,\n",
       "           nan, 17.  , 30.  , 30.  , 24.  , 18.  , 26.  , 28.  , 43.  ,\n",
       "         26.  , 24.  , 54.  , 31.  , 40.  , 22.  , 27.  , 30.  , 22.  ,\n",
       "           nan, 36.  , 61.  , 36.  , 31.  , 16.  ,   nan, 45.5 , 38.  ,\n",
       "         16.  ,   nan,   nan, 29.  , 41.  , 45.  , 45.  ,  2.  , 24.  ,\n",
       "         28.  , 25.  , 36.  , 24.  , 40.  ,   nan,  3.  , 42.  , 23.  ,\n",
       "           nan, 15.  , 25.  ,   nan, 28.  , 22.  , 38.  ,   nan,   nan,\n",
       "         40.  , 29.  , 45.  , 35.  ,   nan, 30.  , 60.  ,   nan,   nan,\n",
       "         24.  , 25.  , 18.  , 19.  , 22.  ,  3.  ,   nan, 22.  , 27.  ,\n",
       "         20.  , 19.  , 42.  ,  1.  , 32.  , 35.  ,   nan, 18.  ,  1.  ,\n",
       "         36.  ,   nan, 17.  , 36.  , 21.  , 28.  , 23.  , 24.  , 22.  ,\n",
       "         31.  , 46.  , 23.  , 28.  , 39.  , 26.  , 21.  , 28.  , 20.  ,\n",
       "         34.  , 51.  ,  3.  , 21.  ,   nan,   nan,   nan, 33.  ,   nan,\n",
       "         44.  ,   nan, 34.  , 18.  , 30.  , 10.  ,   nan, 21.  , 29.  ,\n",
       "         28.  , 18.  ,   nan, 28.  , 19.  ,   nan, 32.  , 28.  ,   nan,\n",
       "         42.  , 17.  , 50.  , 14.  , 21.  , 24.  , 64.  , 31.  , 45.  ,\n",
       "         20.  , 25.  , 28.  ,   nan,  4.  , 13.  , 34.  ,  5.  , 52.  ,\n",
       "         36.  ,   nan, 30.  , 49.  ,   nan, 29.  , 65.  ,   nan, 50.  ,\n",
       "           nan, 48.  , 34.  , 47.  , 48.  ,   nan, 38.  ,   nan, 56.  ,\n",
       "           nan,  0.75,   nan, 38.  , 33.  , 23.  , 22.  ,   nan, 34.  ,\n",
       "         29.  , 22.  ,  2.  ,  9.  ,   nan, 50.  , 63.  , 25.  ,   nan,\n",
       "         35.  , 58.  , 30.  ,  9.  ,   nan, 21.  , 55.  , 71.  , 21.  ,\n",
       "           nan, 54.  ,   nan, 25.  , 24.  , 17.  , 21.  ,   nan, 37.  ,\n",
       "         16.  , 18.  , 33.  ,   nan, 28.  , 26.  , 29.  ,   nan, 36.  ,\n",
       "         54.  , 24.  , 47.  , 34.  ,   nan, 36.  , 32.  , 30.  , 22.  ,\n",
       "           nan, 44.  ,   nan, 40.5 , 50.  ,   nan, 39.  , 23.  ,  2.  ,\n",
       "           nan, 17.  ,   nan, 30.  ,  7.  , 45.  , 30.  ,   nan, 22.  ,\n",
       "         36.  ,  9.  , 11.  , 32.  , 50.  , 64.  , 19.  ,   nan, 33.  ,\n",
       "          8.  , 17.  , 27.  ,   nan, 22.  , 22.  , 62.  , 48.  ,   nan,\n",
       "         39.  , 36.  ,   nan, 40.  , 28.  ,   nan,   nan, 24.  , 19.  ,\n",
       "         29.  ,   nan, 32.  , 62.  , 53.  , 36.  ,   nan, 16.  , 19.  ,\n",
       "         34.  , 39.  ,   nan, 32.  , 25.  , 39.  , 54.  , 36.  ,   nan,\n",
       "         18.  , 47.  , 60.  , 22.  ,   nan, 35.  , 52.  , 47.  ,   nan,\n",
       "         37.  , 36.  ,   nan, 49.  ,   nan, 49.  , 24.  ,   nan,   nan,\n",
       "         44.  , 35.  , 36.  , 30.  , 27.  , 22.  , 40.  , 39.  ,   nan,\n",
       "           nan,   nan, 35.  , 24.  , 34.  , 26.  ,  4.  , 26.  , 27.  ,\n",
       "         42.  , 20.  , 21.  , 21.  , 61.  , 57.  , 21.  , 26.  ,   nan,\n",
       "         80.  , 51.  , 32.  ,   nan,  9.  , 28.  , 32.  , 31.  , 41.  ,\n",
       "           nan, 20.  , 24.  ,  2.  ,   nan,  0.75, 48.  , 19.  , 56.  ,\n",
       "           nan, 23.  ,   nan, 18.  , 21.  ,   nan, 18.  , 24.  ,   nan,\n",
       "         32.  , 23.  , 58.  , 50.  , 40.  , 47.  , 36.  , 20.  , 32.  ,\n",
       "         25.  ,   nan, 43.  ,   nan, 40.  , 31.  , 70.  , 31.  ,   nan,\n",
       "         18.  , 24.5 , 18.  , 43.  , 36.  ,   nan, 27.  , 20.  , 14.  ,\n",
       "         60.  , 25.  , 14.  , 19.  , 18.  , 15.  , 31.  ,  4.  ,   nan,\n",
       "         25.  , 60.  , 52.  , 44.  ,   nan, 49.  , 42.  , 18.  , 35.  ,\n",
       "         18.  , 25.  , 26.  , 39.  , 45.  , 42.  , 22.  ,   nan, 24.  ,\n",
       "           nan, 48.  , 29.  , 52.  , 19.  , 38.  , 27.  ,   nan, 33.  ,\n",
       "          6.  , 17.  , 34.  , 50.  , 27.  , 20.  , 30.  ,   nan, 25.  ,\n",
       "         25.  , 29.  , 11.  ,   nan, 23.  , 23.  , 28.5 , 48.  , 35.  ,\n",
       "           nan,   nan,   nan, 36.  , 21.  , 24.  , 31.  , 70.  , 16.  ,\n",
       "         30.  , 19.  , 31.  ,  4.  ,  6.  , 33.  , 23.  , 48.  ,  0.67,\n",
       "         28.  , 18.  , 34.  , 33.  ,   nan, 41.  , 20.  , 36.  , 16.  ,\n",
       "         51.  ,   nan, 30.5 ,   nan, 32.  , 24.  , 48.  , 57.  ,   nan,\n",
       "         54.  , 18.  ,   nan,  5.  ,   nan, 43.  , 13.  , 17.  , 29.  ,\n",
       "           nan, 25.  , 25.  , 18.  ,  8.  ,  1.  , 46.  ,   nan, 16.  ,\n",
       "           nan,   nan, 25.  , 39.  , 49.  , 31.  , 30.  , 30.  , 34.  ,\n",
       "         31.  , 11.  ,  0.42, 27.  , 31.  , 39.  , 18.  , 39.  , 33.  ,\n",
       "         26.  , 39.  , 35.  ,  6.  , 30.5 ,   nan, 23.  , 31.  , 43.  ,\n",
       "         10.  , 52.  , 27.  , 38.  , 27.  ,  2.  ,   nan,   nan,  1.  ,\n",
       "           nan, 62.  , 15.  ,  0.83,   nan, 23.  , 18.  , 39.  , 21.  ,\n",
       "           nan, 32.  ,   nan, 20.  , 16.  , 30.  , 34.5 , 17.  , 42.  ,\n",
       "           nan, 35.  , 28.  ,   nan,  4.  , 74.  ,  9.  , 16.  , 44.  ,\n",
       "         18.  , 45.  , 51.  , 24.  ,   nan, 41.  , 21.  , 48.  ,   nan,\n",
       "         24.  , 42.  , 27.  , 31.  ,   nan,  4.  , 26.  , 47.  , 33.  ,\n",
       "         47.  , 28.  , 15.  , 20.  , 19.  ,   nan, 56.  , 25.  , 33.  ,\n",
       "         22.  , 28.  , 25.  , 39.  , 27.  , 19.  ,   nan, 26.  , 32.  ])>,\n",
       "  'SibSp': <tf.Tensor: shape=(891,), dtype=int64, numpy=\n",
       "  array([1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0,\n",
       "         0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1,\n",
       "         0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0, 0, 1, 3, 0, 1,\n",
       "         0, 0, 4, 2, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0,\n",
       "         3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
       "         0, 1, 0, 1, 0, 0, 0, 1, 0, 4, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 4, 1, 0, 0, 1,\n",
       "         3, 0, 0, 0, 8, 0, 4, 2, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 8, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "         0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0,\n",
       "         0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 8, 0, 0, 0, 1, 0,\n",
       "         2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "         3, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0, 0, 0, 1, 0, 2, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 5, 0, 0, 0,\n",
       "         1, 3, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 1, 1, 0, 1, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "         1, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1,\n",
       "         0, 1, 0, 0, 3, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "         2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 5, 1, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "         3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0,\n",
       "         1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 4, 1, 0, 0, 0,\n",
       "         8, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 4,\n",
       "         0, 0, 0, 1, 0, 3, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 1, 4, 0, 1, 0, 1, 0, 1, 0,\n",
       "         0, 0, 2, 1, 0, 8, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>,\n",
       "  'Parch': <tf.Tensor: shape=(891,), dtype=int64, numpy=\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 1,\n",
       "         0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
       "         2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 2,\n",
       "         0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 1, 4, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "         1, 0, 0, 0, 2, 0, 2, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 1, 0,\n",
       "         0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "         0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2,\n",
       "         0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 4, 0,\n",
       "         1, 0, 0, 0, 0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "         2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 1, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1,\n",
       "         2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 0, 2,\n",
       "         1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1,\n",
       "         5, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0,\n",
       "         0, 2, 1, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0,\n",
       "         0, 0, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "         2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0,\n",
       "         3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0], dtype=int64)>,\n",
       "  'Fare': <tf.Tensor: shape=(891,), dtype=float64, numpy=\n",
       "  array([  7.25  ,  71.2833,   7.925 ,  53.1   ,   8.05  ,   8.4583,\n",
       "          51.8625,  21.075 ,  11.1333,  30.0708,  16.7   ,  26.55  ,\n",
       "           8.05  ,  31.275 ,   7.8542,  16.    ,  29.125 ,  13.    ,\n",
       "          18.    ,   7.225 ,  26.    ,  13.    ,   8.0292,  35.5   ,\n",
       "          21.075 ,  31.3875,   7.225 , 263.    ,   7.8792,   7.8958,\n",
       "          27.7208, 146.5208,   7.75  ,  10.5   ,  82.1708,  52.    ,\n",
       "           7.2292,   8.05  ,  18.    ,  11.2417,   9.475 ,  21.    ,\n",
       "           7.8958,  41.5792,   7.8792,   8.05  ,  15.5   ,   7.75  ,\n",
       "          21.6792,  17.8   ,  39.6875,   7.8   ,  76.7292,  26.    ,\n",
       "          61.9792,  35.5   ,  10.5   ,   7.2292,  27.75  ,  46.9   ,\n",
       "           7.2292,  80.    ,  83.475 ,  27.9   ,  27.7208,  15.2458,\n",
       "          10.5   ,   8.1583,   7.925 ,   8.6625,  10.5   ,  46.9   ,\n",
       "          73.5   ,  14.4542,  56.4958,   7.65  ,   7.8958,   8.05  ,\n",
       "          29.    ,  12.475 ,   9.    ,   9.5   ,   7.7875,  47.1   ,\n",
       "          10.5   ,  15.85  ,  34.375 ,   8.05  , 263.    ,   8.05  ,\n",
       "           8.05  ,   7.8542,  61.175 ,  20.575 ,   7.25  ,   8.05  ,\n",
       "          34.6542,  63.3583,  23.    ,  26.    ,   7.8958,   7.8958,\n",
       "          77.2875,   8.6542,   7.925 ,   7.8958,   7.65  ,   7.775 ,\n",
       "           7.8958,  24.15  ,  52.    ,  14.4542,   8.05  ,   9.825 ,\n",
       "          14.4583,   7.925 ,   7.75  ,  21.    , 247.5208,  31.275 ,\n",
       "          73.5   ,   8.05  ,  30.0708,  13.    ,  77.2875,  11.2417,\n",
       "           7.75  ,   7.1417,  22.3583,   6.975 ,   7.8958,   7.05  ,\n",
       "          14.5   ,  26.    ,  13.    ,  15.0458,  26.2833,  53.1   ,\n",
       "           9.2167,  79.2   ,  15.2458,   7.75  ,  15.85  ,   6.75  ,\n",
       "          11.5   ,  36.75  ,   7.7958,  34.375 ,  26.    ,  13.    ,\n",
       "          12.525 ,  66.6   ,   8.05  ,  14.5   ,   7.3125,  61.3792,\n",
       "           7.7333,   8.05  ,   8.6625,  69.55  ,  16.1   ,  15.75  ,\n",
       "           7.775 ,   8.6625,  39.6875,  20.525 ,  55.    ,  27.9   ,\n",
       "          25.925 ,  56.4958,  33.5   ,  29.125 ,  11.1333,   7.925 ,\n",
       "          30.6958,   7.8542,  25.4667,  28.7125,  13.    ,   0.    ,\n",
       "          69.55  ,  15.05  ,  31.3875,  39.    ,  22.025 ,  50.    ,\n",
       "          15.5   ,  26.55  ,  15.5   ,   7.8958,  13.    ,  13.    ,\n",
       "           7.8542,  26.    ,  27.7208, 146.5208,   7.75  ,   8.4042,\n",
       "           7.75  ,  13.    ,   9.5   ,  69.55  ,   6.4958,   7.225 ,\n",
       "           8.05  ,  10.4625,  15.85  ,  18.7875,   7.75  ,  31.    ,\n",
       "           7.05  ,  21.    ,   7.25  ,  13.    ,   7.75  , 113.275 ,\n",
       "           7.925 ,  27.    ,  76.2917,  10.5   ,   8.05  ,  13.    ,\n",
       "           8.05  ,   7.8958,  90.    ,   9.35  ,  10.5   ,   7.25  ,\n",
       "          13.    ,  25.4667,  83.475 ,   7.775 ,  13.5   ,  31.3875,\n",
       "          10.5   ,   7.55  ,  26.    ,  26.25  ,  10.5   ,  12.275 ,\n",
       "          14.4542,  15.5   ,  10.5   ,   7.125 ,   7.225 ,  90.    ,\n",
       "           7.775 ,  14.5   ,  52.5542,  26.    ,   7.25  ,  10.4625,\n",
       "          26.55  ,  16.1   ,  20.2125,  15.2458,  79.2   ,  86.5   ,\n",
       "         512.3292,  26.    ,   7.75  ,  31.3875,  79.65  ,   0.    ,\n",
       "           7.75  ,  10.5   ,  39.6875,   7.775 , 153.4625, 135.6333,\n",
       "          31.    ,   0.    ,  19.5   ,  29.7   ,   7.75  ,  77.9583,\n",
       "           7.75  ,   0.    ,  29.125 ,  20.25  ,   7.75  ,   7.8542,\n",
       "           9.5   ,   8.05  ,  26.    ,   8.6625,   9.5   ,   7.8958,\n",
       "          13.    ,   7.75  ,  78.85  ,  91.0792,  12.875 ,   8.85  ,\n",
       "           7.8958,  27.7208,   7.2292, 151.55  ,  30.5   , 247.5208,\n",
       "           7.75  ,  23.25  ,   0.    ,  12.35  ,   8.05  , 151.55  ,\n",
       "         110.8833, 108.9   ,  24.    ,  56.9292,  83.1583, 262.375 ,\n",
       "          26.    ,   7.8958,  26.25  ,   7.8542,  26.    ,  14.    ,\n",
       "         164.8667, 134.5   ,   7.25  ,   7.8958,  12.35  ,  29.    ,\n",
       "          69.55  , 135.6333,   6.2375,  13.    ,  20.525 ,  57.9792,\n",
       "          23.25  ,  28.5   , 153.4625,  18.    , 133.65  ,   7.8958,\n",
       "          66.6   , 134.5   ,   8.05  ,  35.5   ,  26.    , 263.    ,\n",
       "          13.    ,  13.    ,  13.    ,  13.    ,  13.    ,  16.1   ,\n",
       "          15.9   ,   8.6625,   9.225 ,  35.    ,   7.2292,  17.8   ,\n",
       "           7.225 ,   9.5   ,  55.    ,  13.    ,   7.8792,   7.8792,\n",
       "          27.9   ,  27.7208,  14.4542,   7.05  ,  15.5   ,   7.25  ,\n",
       "          75.25  ,   7.2292,   7.75  ,  69.3   ,  55.4417,   6.4958,\n",
       "           8.05  , 135.6333,  21.075 ,  82.1708,   7.25  , 211.5   ,\n",
       "           4.0125,   7.775 , 227.525 ,  15.7417,   7.925 ,  52.    ,\n",
       "           7.8958,  73.5   ,  46.9   ,  13.    ,   7.7292,  12.    ,\n",
       "         120.    ,   7.7958,   7.925 , 113.275 ,  16.7   ,   7.7958,\n",
       "           7.8542,  26.    ,  10.5   ,  12.65  ,   7.925 ,   8.05  ,\n",
       "           9.825 ,  15.85  ,   8.6625,  21.    ,   7.75  ,  18.75  ,\n",
       "           7.775 ,  25.4667,   7.8958,   6.8583,  90.    ,   0.    ,\n",
       "           7.925 ,   8.05  ,  32.5   ,  13.    ,  13.    ,  24.15  ,\n",
       "           7.8958,   7.7333,   7.875 ,  14.4   ,  20.2125,   7.25  ,\n",
       "          26.    ,  26.    ,   7.75  ,   8.05  ,  26.55  ,  16.1   ,\n",
       "          26.    ,   7.125 ,  55.9   , 120.    ,  34.375 ,  18.75  ,\n",
       "         263.    ,  10.5   ,  26.25  ,   9.5   ,   7.775 ,  13.    ,\n",
       "           8.1125,  81.8583,  19.5   ,  26.55  ,  19.2583,  30.5   ,\n",
       "          27.75  ,  19.9667,  27.75  ,  89.1042,   8.05  ,   7.8958,\n",
       "          26.55  ,  51.8625,  10.5   ,   7.75  ,  26.55  ,   8.05  ,\n",
       "          38.5   ,  13.    ,   8.05  ,   7.05  ,   0.    ,  26.55  ,\n",
       "           7.725 ,  19.2583,   7.25  ,   8.6625,  27.75  ,  13.7917,\n",
       "           9.8375,  52.    ,  21.    ,   7.0458,   7.5208,  12.2875,\n",
       "          46.9   ,   0.    ,   8.05  ,   9.5875,  91.0792,  25.4667,\n",
       "          90.    ,  29.7   ,   8.05  ,  15.9   ,  19.9667,   7.25  ,\n",
       "          30.5   ,  49.5042,   8.05  ,  14.4583,  78.2667,  15.1   ,\n",
       "         151.55  ,   7.7958,   8.6625,   7.75  ,   7.6292,   9.5875,\n",
       "          86.5   , 108.9   ,  26.    ,  26.55  ,  22.525 ,  56.4958,\n",
       "           7.75  ,   8.05  ,  26.2875,  59.4   ,   7.4958,  34.0208,\n",
       "          10.5   ,  24.15  ,  26.    ,   7.8958,  93.5   ,   7.8958,\n",
       "           7.225 ,  57.9792,   7.2292,   7.75  ,  10.5   , 221.7792,\n",
       "           7.925 ,  11.5   ,  26.    ,   7.2292,   7.2292,  22.3583,\n",
       "           8.6625,  26.25  ,  26.55  , 106.425 ,  14.5   ,  49.5   ,\n",
       "          71.    ,  31.275 ,  31.275 ,  26.    , 106.425 ,  26.    ,\n",
       "          26.    ,  13.8625,  20.525 ,  36.75  , 110.8833,  26.    ,\n",
       "           7.8292,   7.225 ,   7.775 ,  26.55  ,  39.6   , 227.525 ,\n",
       "          79.65  ,  17.4   ,   7.75  ,   7.8958,  13.5   ,   8.05  ,\n",
       "           8.05  ,  24.15  ,   7.8958,  21.075 ,   7.2292,   7.8542,\n",
       "          10.5   ,  51.4792,  26.3875,   7.75  ,   8.05  ,  14.5   ,\n",
       "          13.    ,  55.9   ,  14.4583,   7.925 ,  30.    , 110.8833,\n",
       "          26.    ,  40.125 ,   8.7125,  79.65  ,  15.    ,  79.2   ,\n",
       "           8.05  ,   8.05  ,   7.125 ,  78.2667,   7.25  ,   7.75  ,\n",
       "          26.    ,  24.15  ,  33.    ,   0.    ,   7.225 ,  56.9292,\n",
       "          27.    ,   7.8958,  42.4   ,   8.05  ,  26.55  ,  15.55  ,\n",
       "           7.8958,  30.5   ,  41.5792, 153.4625,  31.275 ,   7.05  ,\n",
       "          15.5   ,   7.75  ,   8.05  ,  65.    ,  14.4   ,  16.1   ,\n",
       "          39.    ,  10.5   ,  14.4542,  52.5542,  15.7417,   7.8542,\n",
       "          16.1   ,  32.3208,  12.35  ,  77.9583,   7.8958,   7.7333,\n",
       "          30.    ,   7.0542,  30.5   ,   0.    ,  27.9   ,  13.    ,\n",
       "           7.925 ,  26.25  ,  39.6875,  16.1   ,   7.8542,  69.3   ,\n",
       "          27.9   ,  56.4958,  19.2583,  76.7292,   7.8958,  35.5   ,\n",
       "           7.55  ,   7.55  ,   7.8958,  23.    ,   8.4333,   7.8292,\n",
       "           6.75  ,  73.5   ,   7.8958,  15.5   ,  13.    , 113.275 ,\n",
       "         133.65  ,   7.225 ,  25.5875,   7.4958,   7.925 ,  73.5   ,\n",
       "          13.    ,   7.775 ,   8.05  ,  52.    ,  39.    ,  52.    ,\n",
       "          10.5   ,  13.    ,   0.    ,   7.775 ,   8.05  ,   9.8417,\n",
       "          46.9   , 512.3292,   8.1375,  76.7292,   9.225 ,  46.9   ,\n",
       "          39.    ,  41.5792,  39.6875,  10.1708,   7.7958, 211.3375,\n",
       "          57.    ,  13.4167,  56.4958,   7.225 ,  26.55  ,  13.5   ,\n",
       "           8.05  ,   7.7333, 110.8833,   7.65  , 227.525 ,  26.2875,\n",
       "          14.4542,   7.7417,   7.8542,  26.    ,  13.5   ,  26.2875,\n",
       "         151.55  ,  15.2458,  49.5042,  26.55  ,  52.    ,   9.4833,\n",
       "          13.    ,   7.65  , 227.525 ,  10.5   ,  15.5   ,   7.775 ,\n",
       "          33.    ,   7.0542,  13.    ,  13.    ,  53.1   ,   8.6625,\n",
       "          21.    ,   7.7375,  26.    ,   7.925 , 211.3375,  18.7875,\n",
       "           0.    ,  13.    ,  13.    ,  16.1   ,  34.375 , 512.3292,\n",
       "           7.8958,   7.8958,  30.    ,  78.85  , 262.375 ,  16.1   ,\n",
       "           7.925 ,  71.    ,  20.25  ,  13.    ,  53.1   ,   7.75  ,\n",
       "          23.    ,  12.475 ,   9.5   ,   7.8958,  65.    ,  14.5   ,\n",
       "           7.7958,  11.5   ,   8.05  ,  86.5   ,  14.5   ,   7.125 ,\n",
       "           7.2292, 120.    ,   7.775 ,  77.9583,  39.6   ,   7.75  ,\n",
       "          24.15  ,   8.3625,   9.5   ,   7.8542,  10.5   ,   7.225 ,\n",
       "          23.    ,   7.75  ,   7.75  ,  12.475 ,   7.7375, 211.3375,\n",
       "           7.2292,  57.    ,  30.    ,  23.45  ,   7.05  ,   7.25  ,\n",
       "           7.4958,  29.125 ,  20.575 ,  79.2   ,   7.75  ,  26.    ,\n",
       "          69.55  ,  30.6958,   7.8958,  13.    ,  25.9292,   8.6833,\n",
       "           7.2292,  24.15  ,  13.    ,  26.25  , 120.    ,   8.5167,\n",
       "           6.975 ,   7.775 ,   0.    ,   7.775 ,  13.    ,  53.1   ,\n",
       "           7.8875,  24.15  ,  10.5   ,  31.275 ,   8.05  ,   0.    ,\n",
       "           7.925 ,  37.0042,   6.45  ,  27.9   ,  93.5   ,   8.6625,\n",
       "           0.    ,  12.475 ,  39.6875,   6.95  ,  56.4958,  37.0042,\n",
       "           7.75  ,  80.    ,  14.4542,  18.75  ,   7.2292,   7.8542,\n",
       "           8.3   ,  83.1583,   8.6625,   8.05  ,  56.4958,  29.7   ,\n",
       "           7.925 ,  10.5   ,  31.    ,   6.4375,   8.6625,   7.55  ,\n",
       "          69.55  ,   7.8958,  33.    ,  89.1042,  31.275 ,   7.775 ,\n",
       "          15.2458,  39.4   ,  26.    ,   9.35  , 164.8667,  26.55  ,\n",
       "          19.2583,   7.2292,  14.1083,  11.5   ,  25.9292,  69.55  ,\n",
       "          13.    ,  13.    ,  13.8583,  50.4958,   9.5   ,  11.1333,\n",
       "           7.8958,  52.5542,   5.    ,   9.    ,  24.    ,   7.225 ,\n",
       "           9.8458,   7.8958,   7.8958,  83.1583,  26.    ,   7.8958,\n",
       "          10.5167,  10.5   ,   7.05  ,  29.125 ,  13.    ,  30.    ,\n",
       "          23.45  ,  30.    ,   7.75  ])>,\n",
       "  'Embarked': <tf.Tensor: shape=(891,), dtype=string, numpy=\n",
       "  array([b'S', b'C', b'S', b'S', b'S', b'Q', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'C', b'S', b'Q', b'S', b'C', b'C', b'Q',\n",
       "         b'S', b'C', b'S', b'C', b'S', b'S', b'C', b'S', b'S', b'C', b'C',\n",
       "         b'Q', b'S', b'Q', b'Q', b'C', b'S', b'S', b'S', b'C', b'S', b'C',\n",
       "         b'S', b'S', b'C', b'S', b'S', b'C', b'D', b'S', b'S', b'C', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'C', b'S', b'S', b'C', b'S', b'Q', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'C', b'S', b'S', b'C', b'Q', b'S', b'C', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'C', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'C', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'C', b'S',\n",
       "         b'S', b'C', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'Q', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'Q',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'Q', b'C', b'S', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'Q',\n",
       "         b'S', b'S', b'C', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'C', b'C', b'S', b'C', b'S', b'Q', b'S', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'Q',\n",
       "         b'S', b'S', b'S', b'Q', b'S', b'Q', b'S', b'S', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'Q', b'S', b'C', b'C', b'S', b'S', b'C', b'C',\n",
       "         b'S', b'S', b'C', b'Q', b'Q', b'S', b'Q', b'S', b'S', b'C', b'C',\n",
       "         b'C', b'C', b'C', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S', b'S', b'C',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'C', b'S', b'S', b'S', b'Q', b'Q', b'S', b'C', b'C',\n",
       "         b'S', b'Q', b'S', b'C', b'C', b'Q', b'C', b'C', b'S', b'S', b'C',\n",
       "         b'S', b'C', b'S', b'C', b'C', b'S', b'C', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'Q', b'C', b'S', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'C', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'C', b'C', b'S', b'C', b'S', b'S', b'S', b'Q', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'Q', b'C', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'C', b'S', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'C', b'C', b'C', b'Q', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'C', b'C', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'C', b'S', b'Q', b'C', b'S', b'S', b'C', b'C', b'S', b'S', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'C', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'S', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'C', b'C', b'S', b'S', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'C', b'S', b'C', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'C', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S', b'Q', b'S', b'C',\n",
       "         b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'Q', b'C',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'Q', b'C', b'S', b'C', b'S', b'C', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'C', b'S', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'Q', b'Q', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'Q', b'S', b'Q', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'C', b'Q', b'S',\n",
       "         b'S', b'C', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'Q', b'S', b'C', b'Q', b'D', b'C', b'S', b'C', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'C', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'C', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'S', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'S', b'C', b'Q'],\n",
       "        dtype=object)>}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(titanic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = kr.models.load_model(filepath=inference_model_path)\n",
    "training_model = kr.models.load_model(filepath=training_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pclass': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2], dtype=int64)>,\n",
       " 'Sex': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'female'], dtype=object)>,\n",
       " 'Age': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([4.])>,\n",
       " 'SibSp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1], dtype=int64)>,\n",
       " 'Parch': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1], dtype=int64)>,\n",
       " 'Fare': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([23.])>,\n",
       " 'Embarked': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'S'], dtype=object)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = titanic_data_test.sample(n=1)\n",
    "input_dict = {name: tf.convert_to_tensor(value) for name, value in sample.items()}\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.993184]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = inference_model.predict(input_dict)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05701197],\n",
       "       [0.9815234 ],\n",
       "       [0.75580287],\n",
       "       [0.97204787],\n",
       "       [0.07413565],\n",
       "       [0.0681882 ],\n",
       "       [0.23828526],\n",
       "       [0.11711147],\n",
       "       [0.89393795],\n",
       "       [0.9784754 ],\n",
       "       [0.6905775 ],\n",
       "       [0.97732615],\n",
       "       [0.07377546],\n",
       "       [0.01028379],\n",
       "       [0.36300373],\n",
       "       [0.8753906 ],\n",
       "       [0.04339106],\n",
       "       [0.19981164],\n",
       "       [0.5252084 ],\n",
       "       [0.7525909 ],\n",
       "       [0.05060114],\n",
       "       [0.05523799],\n",
       "       [0.9113914 ],\n",
       "       [0.42637715],\n",
       "       [0.19293302],\n",
       "       [0.12480571],\n",
       "       [0.10533528],\n",
       "       [0.01470271],\n",
       "       [0.9115223 ],\n",
       "       [0.12220655],\n",
       "       [0.3062078 ],\n",
       "       [0.9901994 ],\n",
       "       [0.9116349 ],\n",
       "       [0.0559787 ],\n",
       "       [0.7863868 ],\n",
       "       [0.32528707],\n",
       "       [0.10533631],\n",
       "       [0.07377546],\n",
       "       [0.28653058],\n",
       "       [0.5844018 ],\n",
       "       [0.3178981 ],\n",
       "       [0.75665677],\n",
       "       [0.10549946],\n",
       "       [0.9875815 ],\n",
       "       [0.4604545 ],\n",
       "       [0.12221698],\n",
       "       [0.07707734],\n",
       "       [0.9116349 ],\n",
       "       [0.23229979],\n",
       "       [0.3889504 ],\n",
       "       [0.05867792],\n",
       "       [0.07367533],\n",
       "       [0.98335534],\n",
       "       [0.9869133 ],\n",
       "       [0.1126862 ],\n",
       "       [0.30955073],\n",
       "       [0.96371263],\n",
       "       [0.2147619 ],\n",
       "       [0.9907943 ],\n",
       "       [0.02843964],\n",
       "       [0.2841488 ],\n",
       "       [0.99332917],\n",
       "       [0.29401845],\n",
       "       [0.1011811 ],\n",
       "       [0.13922036],\n",
       "       [0.5619972 ],\n",
       "       [0.97457784],\n",
       "       [0.07381885],\n",
       "       [0.15419503],\n",
       "       [0.03260846],\n",
       "       [0.09135986],\n",
       "       [0.15900606],\n",
       "       [0.04058167],\n",
       "       [0.11927892],\n",
       "       [0.42690524],\n",
       "       [0.1766597 ],\n",
       "       [0.12220655],\n",
       "       [0.12221698],\n",
       "       [0.9842307 ],\n",
       "       [0.57530516],\n",
       "       [0.07412294],\n",
       "       [0.33109325],\n",
       "       [0.91160226],\n",
       "       [0.45934457],\n",
       "       [0.9851407 ],\n",
       "       [0.84377944],\n",
       "       [0.44601777],\n",
       "       [0.12221698],\n",
       "       [0.9929338 ],\n",
       "       [0.1777236 ],\n",
       "       [0.32487252],\n",
       "       [0.07369703],\n",
       "       [0.3044577 ],\n",
       "       [0.08899103],\n",
       "       [0.07445487],\n",
       "       [0.12221698],\n",
       "       [0.28475225],\n",
       "       [0.8294566 ],\n",
       "       [0.95927054],\n",
       "       [0.03737288],\n",
       "       [0.5581437 ],\n",
       "       [0.12220655],\n",
       "       [0.07492596],\n",
       "       [0.327487  ],\n",
       "       [0.03229395],\n",
       "       [0.3242071 ],\n",
       "       [0.54217005],\n",
       "       [0.12219018],\n",
       "       [0.07419709],\n",
       "       [0.93886906],\n",
       "       [0.23788449],\n",
       "       [0.5865549 ],\n",
       "       [0.07377546],\n",
       "       [0.3961971 ],\n",
       "       [0.7556485 ],\n",
       "       [0.07372536],\n",
       "       [0.02992912],\n",
       "       [0.13818185],\n",
       "       [0.5582419 ],\n",
       "       [0.17079006],\n",
       "       [0.03558112],\n",
       "       [0.12221698],\n",
       "       [0.14202529],\n",
       "       [0.9752322 ],\n",
       "       [0.1008175 ],\n",
       "       [0.16738483],\n",
       "       [0.06833693],\n",
       "       [0.17531498],\n",
       "       [0.7905465 ],\n",
       "       [0.07456488],\n",
       "       [0.21580936],\n",
       "       [0.07337575],\n",
       "       [0.33258644],\n",
       "       [0.9869133 ],\n",
       "       [0.07284082],\n",
       "       [0.1049886 ],\n",
       "       [0.9881574 ],\n",
       "       [0.32245716],\n",
       "       [0.12228157],\n",
       "       [0.75742704],\n",
       "       [0.54502285],\n",
       "       [0.54220307],\n",
       "       [0.6404333 ],\n",
       "       [0.03061278],\n",
       "       [0.07597776],\n",
       "       [0.07512127],\n",
       "       [0.17704692],\n",
       "       [0.21019341],\n",
       "       [0.08002587],\n",
       "       [0.05523799],\n",
       "       [0.05539177],\n",
       "       [0.9822752 ],\n",
       "       [0.07413565],\n",
       "       [0.09171239],\n",
       "       [0.12212759],\n",
       "       [0.11314794],\n",
       "       [0.91164947],\n",
       "       [0.32487252],\n",
       "       [0.12225091],\n",
       "       [0.00939388],\n",
       "       [0.08709984],\n",
       "       [0.87503713],\n",
       "       [0.17699163],\n",
       "       [0.12225091],\n",
       "       [0.05867792],\n",
       "       [0.8062311 ],\n",
       "       [0.99261725],\n",
       "       [0.1223208 ],\n",
       "       [0.314156  ],\n",
       "       [0.42690524],\n",
       "       [0.32126543],\n",
       "       [0.04339106],\n",
       "       [0.6812084 ],\n",
       "       [0.07372536],\n",
       "       [0.29695836],\n",
       "       [0.05883616],\n",
       "       [0.12201498],\n",
       "       [0.92669076],\n",
       "       [0.09313286],\n",
       "       [0.07740568],\n",
       "       [0.06529884],\n",
       "       [0.19519539],\n",
       "       [0.05680207],\n",
       "       [0.85874605],\n",
       "       [0.52968657],\n",
       "       [0.29538733],\n",
       "       [0.94495904],\n",
       "       [0.35037363],\n",
       "       [0.01751247],\n",
       "       [0.07419709],\n",
       "       [0.9752322 ],\n",
       "       [0.07457212],\n",
       "       [0.3979898 ],\n",
       "       [0.94780165],\n",
       "       [0.9262409 ],\n",
       "       [0.9874514 ],\n",
       "       [0.06833693],\n",
       "       [0.09114505],\n",
       "       [0.9116349 ],\n",
       "       [0.75355864],\n",
       "       [0.33109325],\n",
       "       [0.00939388],\n",
       "       [0.07475694],\n",
       "       [0.11204709],\n",
       "       [0.07377546],\n",
       "       [0.7082809 ],\n",
       "       [0.14380804],\n",
       "       [0.34724215],\n",
       "       [0.9116349 ],\n",
       "       [0.29602182],\n",
       "       [0.17507328],\n",
       "       [0.8810868 ],\n",
       "       [0.07345554],\n",
       "       [0.09313286],\n",
       "       [0.07574843],\n",
       "       [0.99734473],\n",
       "       [0.75580287],\n",
       "       [0.03719218],\n",
       "       [0.9942685 ],\n",
       "       [0.09135986],\n",
       "       [0.12221698],\n",
       "       [0.07284082],\n",
       "       [0.07413565],\n",
       "       [0.12220655],\n",
       "       [0.29180145],\n",
       "       [0.07423103],\n",
       "       [0.07687405],\n",
       "       [0.07345554],\n",
       "       [0.07457212],\n",
       "       [0.19829836],\n",
       "       [0.9820483 ],\n",
       "       [0.3236863 ],\n",
       "       [0.05507655],\n",
       "       [0.1708453 ],\n",
       "       [0.07200073],\n",
       "       [0.3622504 ],\n",
       "       [0.03737288],\n",
       "       [0.98629487],\n",
       "       [0.07687405],\n",
       "       [0.09261557],\n",
       "       [0.5865549 ],\n",
       "       [0.94495904],\n",
       "       [0.09135986],\n",
       "       [0.07340567],\n",
       "       [0.21475531],\n",
       "       [0.07263036],\n",
       "       [0.75555885],\n",
       "       [0.98583204],\n",
       "       [0.37183   ],\n",
       "       [0.03737288],\n",
       "       [0.12211913],\n",
       "       [0.5547657 ],\n",
       "       [0.35037363],\n",
       "       [0.14421646],\n",
       "       [0.2771392 ],\n",
       "       [0.88632524],\n",
       "       [0.97884035],\n",
       "       [0.9920422 ],\n",
       "       [0.9995992 ],\n",
       "       [0.96080977],\n",
       "       [0.06833693],\n",
       "       [0.05680207],\n",
       "       [0.21264438],\n",
       "       [0.3017934 ],\n",
       "       [0.9116349 ],\n",
       "       [0.0559787 ],\n",
       "       [0.05867792],\n",
       "       [0.07438628],\n",
       "       [0.9913311 ],\n",
       "       [0.98827016],\n",
       "       [0.31241605],\n",
       "       [0.15719616],\n",
       "       [0.9586056 ],\n",
       "       [0.14885877],\n",
       "       [0.9116349 ],\n",
       "       [0.9805924 ],\n",
       "       [0.3289593 ],\n",
       "       [0.21062413],\n",
       "       [0.04339106],\n",
       "       [0.41188157],\n",
       "       [0.02992912],\n",
       "       [0.32402775],\n",
       "       [0.12229732],\n",
       "       [0.07377546],\n",
       "       [0.31413525],\n",
       "       [0.21701872],\n",
       "       [0.33109325],\n",
       "       [0.07371368],\n",
       "       [0.05523799],\n",
       "       [0.4603195 ],\n",
       "       [0.95495504],\n",
       "       [0.9838335 ],\n",
       "       [0.09959015],\n",
       "       [0.7573716 ],\n",
       "       [0.17731293],\n",
       "       [0.13922036],\n",
       "       [0.32615617],\n",
       "       [0.9809109 ],\n",
       "       [0.3125904 ],\n",
       "       [0.9854981 ],\n",
       "       [0.9116349 ],\n",
       "       [0.08410689],\n",
       "       [0.07061406],\n",
       "       [0.9788374 ],\n",
       "       [0.12221698],\n",
       "       [0.94400334],\n",
       "       [0.9833612 ],\n",
       "       [0.9842001 ],\n",
       "       [0.13647112],\n",
       "       [0.9923313 ],\n",
       "       [0.96663785],\n",
       "       [0.98703885],\n",
       "       [0.9546435 ],\n",
       "       [0.3242071 ],\n",
       "       [0.0507458 ],\n",
       "       [0.7556877 ],\n",
       "       [0.7545827 ],\n",
       "       [0.05491559],\n",
       "       [0.94995636],\n",
       "       [0.99248433],\n",
       "       [0.07345554],\n",
       "       [0.17731293],\n",
       "       [0.8799656 ],\n",
       "       [0.9705555 ],\n",
       "       [0.00939388],\n",
       "       [0.98697984],\n",
       "       [0.07486065],\n",
       "       [0.8714669 ],\n",
       "       [0.613449  ],\n",
       "       [0.9819492 ],\n",
       "       [0.867385  ],\n",
       "       [0.34801272],\n",
       "       [0.0365105 ],\n",
       "       [0.17432813],\n",
       "       [0.9869153 ],\n",
       "       [0.12220655],\n",
       "       [0.44682664],\n",
       "       [0.9869296 ],\n",
       "       [0.07413565],\n",
       "       [0.31033623],\n",
       "       [0.94780165],\n",
       "       [0.9929338 ],\n",
       "       [0.09313286],\n",
       "       [0.07284082],\n",
       "       [0.05523799],\n",
       "       [0.75355864],\n",
       "       [0.8714669 ],\n",
       "       [0.67542934],\n",
       "       [0.58759165],\n",
       "       [0.0738921 ],\n",
       "       [0.18087782],\n",
       "       [0.31004566],\n",
       "       [0.5493821 ],\n",
       "       [0.08156281],\n",
       "       [0.10533528],\n",
       "       [0.33109325],\n",
       "       [0.9895046 ],\n",
       "       [0.8714669 ],\n",
       "       [0.9115223 ],\n",
       "       [0.9115223 ],\n",
       "       [0.02014532],\n",
       "       [0.13987516],\n",
       "       [0.39730608],\n",
       "       [0.07453484],\n",
       "       [0.07707734],\n",
       "       [0.3214278 ],\n",
       "       [0.98290837],\n",
       "       [0.75259066],\n",
       "       [0.9116349 ],\n",
       "       [0.9647263 ],\n",
       "       [0.8865779 ],\n",
       "       [0.05696825],\n",
       "       [0.07377546],\n",
       "       [0.06806669],\n",
       "       [0.19293302],\n",
       "       [0.9822607 ],\n",
       "       [0.542038  ],\n",
       "       [0.06067054],\n",
       "       [0.28326923],\n",
       "       [0.07366531],\n",
       "       [0.99316055],\n",
       "       [0.54547596],\n",
       "       [0.3243331 ],\n",
       "       [0.9718552 ],\n",
       "       [0.12220655],\n",
       "       [0.04058167],\n",
       "       [0.02843964],\n",
       "       [0.8714669 ],\n",
       "       [0.06834129],\n",
       "       [0.9753006 ],\n",
       "       [0.07065812],\n",
       "       [0.07367367],\n",
       "       [0.06303511],\n",
       "       [0.9815488 ],\n",
       "       [0.89486593],\n",
       "       [0.07367367],\n",
       "       [0.5579759 ],\n",
       "       [0.05060114],\n",
       "       [0.07200073],\n",
       "       [0.9751416 ],\n",
       "       [0.07418545],\n",
       "       [0.1777236 ],\n",
       "       [0.3961971 ],\n",
       "       [0.14380804],\n",
       "       [0.54250395],\n",
       "       [0.03828912],\n",
       "       [0.07425522],\n",
       "       [0.95088047],\n",
       "       [0.07366531],\n",
       "       [0.19829836],\n",
       "       [0.12220655],\n",
       "       [0.0685246 ],\n",
       "       [0.95612985],\n",
       "       [0.21062413],\n",
       "       [0.07418545],\n",
       "       [0.36350477],\n",
       "       [0.9496578 ],\n",
       "       [0.98482877],\n",
       "       [0.09313286],\n",
       "       [0.52780354],\n",
       "       [0.10549946],\n",
       "       [0.0303579 ],\n",
       "       [0.32411742],\n",
       "       [0.57719946],\n",
       "       [0.05797482],\n",
       "       [0.12211913],\n",
       "       [0.9869133 ],\n",
       "       [0.9579857 ],\n",
       "       [0.06833693],\n",
       "       [0.32487252],\n",
       "       [0.39541402],\n",
       "       [0.67542934],\n",
       "       [0.83609796],\n",
       "       [0.12210223],\n",
       "       [0.31611794],\n",
       "       [0.9839795 ],\n",
       "       [0.65027684],\n",
       "       [0.9886987 ],\n",
       "       [0.00562853],\n",
       "       [0.09135986],\n",
       "       [0.95219684],\n",
       "       [0.07427739],\n",
       "       [0.07438628],\n",
       "       [0.9752322 ],\n",
       "       [0.12222043],\n",
       "       [0.9659757 ],\n",
       "       [0.9911367 ],\n",
       "       [0.35037363],\n",
       "       [0.7686117 ],\n",
       "       [0.33803028],\n",
       "       [0.05692883],\n",
       "       [0.19291356],\n",
       "       [0.36884874],\n",
       "       [0.69929475],\n",
       "       [0.12221698],\n",
       "       [0.21580936],\n",
       "       [0.35037363],\n",
       "       [0.9894276 ],\n",
       "       [0.8698049 ],\n",
       "       [0.06833693],\n",
       "       [0.35037363],\n",
       "       [0.07413565],\n",
       "       [0.2947653 ],\n",
       "       [0.05523799],\n",
       "       [0.12221698],\n",
       "       [0.07453484],\n",
       "       [0.21062413],\n",
       "       [0.35037363],\n",
       "       [0.06834217],\n",
       "       [0.7686117 ],\n",
       "       [0.12211913],\n",
       "       [0.0738921 ],\n",
       "       [0.9670705 ],\n",
       "       [0.8138919 ],\n",
       "       [0.54289156],\n",
       "       [0.29335257],\n",
       "       [0.03828912],\n",
       "       [0.13003698],\n",
       "       [0.07356368],\n",
       "       [0.71470964],\n",
       "       [0.02843964],\n",
       "       [0.21062413],\n",
       "       [0.07413565],\n",
       "       [0.3335656 ],\n",
       "       [0.8909627 ],\n",
       "       [0.19829836],\n",
       "       [0.9833088 ],\n",
       "       [0.30003637],\n",
       "       [0.32487252],\n",
       "       [0.58759165],\n",
       "       [0.19291356],\n",
       "       [0.07345554],\n",
       "       [0.33803028],\n",
       "       [0.24055664],\n",
       "       [0.07377546],\n",
       "       [0.10538472],\n",
       "       [0.98380786],\n",
       "       [0.12301466],\n",
       "       [0.929775  ],\n",
       "       [0.17704692],\n",
       "       [0.12225091],\n",
       "       [0.4603195 ],\n",
       "       [0.91174006],\n",
       "       [0.3335656 ],\n",
       "       [0.9874366 ],\n",
       "       [0.13685517],\n",
       "       [0.92939496],\n",
       "       [0.31396914],\n",
       "       [0.37870377],\n",
       "       [0.33168054],\n",
       "       [0.33260652],\n",
       "       [0.12221698],\n",
       "       [0.35064858],\n",
       "       [0.97641253],\n",
       "       [0.17625092],\n",
       "       [0.31839994],\n",
       "       [0.8698049 ],\n",
       "       [0.06515487],\n",
       "       [0.83609796],\n",
       "       [0.3242071 ],\n",
       "       [0.99273914],\n",
       "       [0.07371368],\n",
       "       [0.10533528],\n",
       "       [0.96113425],\n",
       "       [0.10533631],\n",
       "       [0.02992912],\n",
       "       [0.8698049 ],\n",
       "       [0.14051816],\n",
       "       [0.07418545],\n",
       "       [0.02941039],\n",
       "       [0.99310136],\n",
       "       [0.10533631],\n",
       "       [0.5493821 ],\n",
       "       [0.5551696 ],\n",
       "       [0.56116956],\n",
       "       [0.98629487],\n",
       "       [0.35037363],\n",
       "       [0.99640423],\n",
       "       [0.12290046],\n",
       "       [0.9803119 ],\n",
       "       [0.9876609 ],\n",
       "       [0.17079006],\n",
       "       [0.17079006],\n",
       "       [0.14792015],\n",
       "       [0.6688498 ],\n",
       "       [0.35094997],\n",
       "       [0.9189257 ],\n",
       "       [0.19572727],\n",
       "       [0.12899637],\n",
       "       [0.94381183],\n",
       "       [0.39288765],\n",
       "       [0.07745852],\n",
       "       [0.06832028],\n",
       "       [0.2841512 ],\n",
       "       [0.54221123],\n",
       "       [0.35037363],\n",
       "       [0.9648247 ],\n",
       "       [0.09956629],\n",
       "       [0.9846272 ],\n",
       "       [0.3426598 ],\n",
       "       [0.06833693],\n",
       "       [0.07419709],\n",
       "       [0.09349117],\n",
       "       [0.12221698],\n",
       "       [0.36350477],\n",
       "       [0.03627542],\n",
       "       [0.07371368],\n",
       "       [0.05175973],\n",
       "       [0.10533631],\n",
       "       [0.32402775],\n",
       "       [0.0559787 ],\n",
       "       [0.94559973],\n",
       "       [0.35054386],\n",
       "       [0.9116349 ],\n",
       "       [0.12221698],\n",
       "       [0.07451294],\n",
       "       [0.8714669 ],\n",
       "       [0.9725324 ],\n",
       "       [0.58655834],\n",
       "       [0.3243331 ],\n",
       "       [0.95325315],\n",
       "       [0.9888812 ],\n",
       "       [0.05060114],\n",
       "       [0.26770383],\n",
       "       [0.10569956],\n",
       "       [0.9834598 ],\n",
       "       [0.05459495],\n",
       "       [0.505762  ],\n",
       "       [0.07377546],\n",
       "       [0.12221698],\n",
       "       [0.07450484],\n",
       "       [0.98380786],\n",
       "       [0.07445487],\n",
       "       [0.27523273],\n",
       "       [0.03737288],\n",
       "       [0.05440122],\n",
       "       [0.98252577],\n",
       "       [0.07740568],\n",
       "       [0.10533528],\n",
       "       [0.6725904 ],\n",
       "       [0.9542369 ],\n",
       "       [0.12220655],\n",
       "       [0.30276388],\n",
       "       [0.07413565],\n",
       "       [0.30989206],\n",
       "       [0.05091691],\n",
       "       [0.3242071 ],\n",
       "       [0.86680317],\n",
       "       [0.9884124 ],\n",
       "       [0.9906433 ],\n",
       "       [0.12488308],\n",
       "       [0.12209211],\n",
       "       [0.94495904],\n",
       "       [0.06833693],\n",
       "       [0.07413565],\n",
       "       [0.97504175],\n",
       "       [0.05656036],\n",
       "       [0.6410135 ],\n",
       "       [0.9898496 ],\n",
       "       [0.07200073],\n",
       "       [0.11927892],\n",
       "       [0.32385963],\n",
       "       [0.17738774],\n",
       "       [0.07369703],\n",
       "       [0.07451948],\n",
       "       [0.3278033 ],\n",
       "       [0.022188  ],\n",
       "       [0.98572844],\n",
       "       [0.17731293],\n",
       "       [0.06834045],\n",
       "       [0.34086588],\n",
       "       [0.07453316],\n",
       "       [0.3823474 ],\n",
       "       [0.31461155],\n",
       "       [0.17675932],\n",
       "       [0.9752322 ],\n",
       "       [0.3243331 ],\n",
       "       [0.19437227],\n",
       "       [0.08237901],\n",
       "       [0.18626787],\n",
       "       [0.07369703],\n",
       "       [0.9647263 ],\n",
       "       [0.17675932],\n",
       "       [0.13529949],\n",
       "       [0.7686117 ],\n",
       "       [0.7100936 ],\n",
       "       [0.07371368],\n",
       "       [0.28207818],\n",
       "       [0.12215972],\n",
       "       [0.75519264],\n",
       "       [0.12220655],\n",
       "       [0.98046166],\n",
       "       [0.07392917],\n",
       "       [0.9115659 ],\n",
       "       [0.45927432],\n",
       "       [0.05623684],\n",
       "       [0.12220655],\n",
       "       [0.17916429],\n",
       "       [0.07284082],\n",
       "       [0.05861602],\n",
       "       [0.75925463],\n",
       "       [0.11204709],\n",
       "       [0.35138252],\n",
       "       [0.07435664],\n",
       "       [0.05705108],\n",
       "       [0.16392092],\n",
       "       [0.07284082],\n",
       "       [0.12219018],\n",
       "       [0.07413565],\n",
       "       [0.9894316 ],\n",
       "       [0.94746566],\n",
       "       [0.38870052],\n",
       "       [0.0559787 ],\n",
       "       [0.09313286],\n",
       "       [0.21062413],\n",
       "       [0.07366531],\n",
       "       [0.1777236 ],\n",
       "       [0.54289293],\n",
       "       [0.06314792],\n",
       "       [0.8984816 ],\n",
       "       [0.9112968 ],\n",
       "       [0.7606669 ],\n",
       "       [0.0741924 ],\n",
       "       [0.02843964],\n",
       "       [0.04582555],\n",
       "       [0.13281438],\n",
       "       [0.05867792],\n",
       "       [0.07448325],\n",
       "       [0.07367367],\n",
       "       [0.9955633 ],\n",
       "       [0.405339  ],\n",
       "       [0.8453197 ],\n",
       "       [0.13529949],\n",
       "       [0.32614267],\n",
       "       [0.35037363],\n",
       "       [0.05507655],\n",
       "       [0.07413565],\n",
       "       [0.91164947],\n",
       "       [0.2753014 ],\n",
       "       [0.07429512],\n",
       "       [0.98972857],\n",
       "       [0.35064858],\n",
       "       [0.81434613],\n",
       "       [0.04459013],\n",
       "       [0.07444003],\n",
       "       [0.05060114],\n",
       "       [0.8719385 ],\n",
       "       [0.35064858],\n",
       "       [0.9817897 ],\n",
       "       [0.5619972 ],\n",
       "       [0.9598025 ],\n",
       "       [0.31396914],\n",
       "       [0.32528707],\n",
       "       [0.33102646],\n",
       "       [0.05523799],\n",
       "       [0.07361534],\n",
       "       [0.99316055],\n",
       "       [0.75587326],\n",
       "       [0.06681804],\n",
       "       [0.3236863 ],\n",
       "       [0.9905325 ],\n",
       "       [0.17206782],\n",
       "       [0.05523799],\n",
       "       [0.05523799],\n",
       "       [0.84316814],\n",
       "       [0.07401884],\n",
       "       [0.987706  ],\n",
       "       [0.91164577],\n",
       "       [0.04751126],\n",
       "       [0.61963636],\n",
       "       [0.99841166],\n",
       "       [0.10386207],\n",
       "       [0.21062413],\n",
       "       [0.07284082],\n",
       "       [0.07284082],\n",
       "       [0.356333  ],\n",
       "       [0.15818793],\n",
       "       [0.9749742 ],\n",
       "       [0.12220655],\n",
       "       [0.12220655],\n",
       "       [0.31276467],\n",
       "       [0.29550973],\n",
       "       [0.98703885],\n",
       "       [0.08026129],\n",
       "       [0.3243331 ],\n",
       "       [0.26512775],\n",
       "       [0.59144616],\n",
       "       [0.9752322 ],\n",
       "       [0.1761853 ],\n",
       "       [0.33260652],\n",
       "       [0.993184  ],\n",
       "       [0.5879291 ],\n",
       "       [0.33109325],\n",
       "       [0.17731293],\n",
       "       [0.95196617],\n",
       "       [0.9529196 ],\n",
       "       [0.3237759 ],\n",
       "       [0.07597776],\n",
       "       [0.07413565],\n",
       "       [0.9920422 ],\n",
       "       [0.12290046],\n",
       "       [0.07450484],\n",
       "       [0.2841488 ],\n",
       "       [0.98735964],\n",
       "       [0.12219018],\n",
       "       [0.9805924 ],\n",
       "       [0.1427444 ],\n",
       "       [0.31773117],\n",
       "       [0.07905652],\n",
       "       [0.32622343],\n",
       "       [0.18162231],\n",
       "       [0.07421366],\n",
       "       [0.8698049 ],\n",
       "       [0.10533528],\n",
       "       [0.88044775],\n",
       "       [0.07365532],\n",
       "       [0.06833693],\n",
       "       [0.37536415],\n",
       "       [0.06833955],\n",
       "       [0.9944945 ],\n",
       "       [0.75259066],\n",
       "       [0.9895885 ],\n",
       "       [0.4087127 ],\n",
       "       [0.5437151 ],\n",
       "       [0.17507328],\n",
       "       [0.17560086],\n",
       "       [0.54211915],\n",
       "       [0.04339106],\n",
       "       [0.5403022 ],\n",
       "       [0.19266875],\n",
       "       [0.06833693],\n",
       "       [0.19026795],\n",
       "       [0.06529884],\n",
       "       [0.13956895],\n",
       "       [0.17731293],\n",
       "       [0.05523799],\n",
       "       [0.97725385],\n",
       "       [0.5612469 ],\n",
       "       [0.2147619 ],\n",
       "       [0.6355779 ],\n",
       "       [0.05523799],\n",
       "       [0.97719693],\n",
       "       [0.9664029 ],\n",
       "       [0.46868083],\n",
       "       [0.17487577],\n",
       "       [0.3236863 ],\n",
       "       [0.3017934 ],\n",
       "       [0.54221123],\n",
       "       [0.05523799],\n",
       "       [0.99107873],\n",
       "       [0.17729087],\n",
       "       [0.06780563],\n",
       "       [0.0559787 ],\n",
       "       [0.17079006],\n",
       "       [0.32487252],\n",
       "       [0.31461155],\n",
       "       [0.75580287],\n",
       "       [0.14345333],\n",
       "       [0.07477532],\n",
       "       [0.1011811 ],\n",
       "       [0.98563075],\n",
       "       [0.17936237],\n",
       "       [0.3017934 ],\n",
       "       [0.8750349 ],\n",
       "       [0.05867792],\n",
       "       [0.06850526],\n",
       "       [0.13529949],\n",
       "       [0.96484596],\n",
       "       [0.06833693],\n",
       "       [0.99332917],\n",
       "       [0.5865549 ],\n",
       "       [0.95088047],\n",
       "       [0.10533631],\n",
       "       [0.17720218],\n",
       "       [0.07387569],\n",
       "       [0.9848496 ],\n",
       "       [0.07401884],\n",
       "       [0.12221698],\n",
       "       [0.42690524],\n",
       "       [0.13945217],\n",
       "       [0.07372536],\n",
       "       [0.20178545],\n",
       "       [0.9884739 ],\n",
       "       [0.11277352],\n",
       "       [0.12225091],\n",
       "       [0.07433501],\n",
       "       [0.00939388],\n",
       "       [0.11143152],\n",
       "       [0.23974699],\n",
       "       [0.9813218 ],\n",
       "       [0.0567934 ],\n",
       "       [0.07424525],\n",
       "       [0.77007735],\n",
       "       [0.99360746],\n",
       "       [0.83609796],\n",
       "       [0.7771152 ],\n",
       "       [0.9936824 ],\n",
       "       [0.35037363],\n",
       "       [0.96339196],\n",
       "       [0.10533631],\n",
       "       [0.03250035],\n",
       "       [0.06426577],\n",
       "       [0.97725385],\n",
       "       [0.06529884],\n",
       "       [0.07284082],\n",
       "       [0.8714669 ],\n",
       "       [0.8615645 ],\n",
       "       [0.46691442],\n",
       "       [0.12229732],\n",
       "       [0.57961845],\n",
       "       [0.17731293],\n",
       "       [0.98336756],\n",
       "       [0.31594384],\n",
       "       [0.07375826],\n",
       "       [0.9895858 ],\n",
       "       [0.7525909 ],\n",
       "       [0.07438441],\n",
       "       [0.07371368],\n",
       "       [0.12220655],\n",
       "       [0.9696865 ],\n",
       "       [0.9397747 ],\n",
       "       [0.3242071 ],\n",
       "       [0.5431155 ],\n",
       "       [0.09135986],\n",
       "       [0.17507328],\n",
       "       [0.03481069],\n",
       "       [0.07284082],\n",
       "       [0.9815844 ],\n",
       "       [0.4060215 ],\n",
       "       [0.8535656 ],\n",
       "       [0.33260646]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = inference_model.predict(x=titanic_dataset)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "       508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n",
       "       521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533,\n",
       "       534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546,\n",
       "       547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
       "       560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
       "       573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585,\n",
       "       586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598,\n",
       "       599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611,\n",
       "       612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624,\n",
       "       625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637,\n",
       "       638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650,\n",
       "       651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663,\n",
       "       664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676,\n",
       "       677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689,\n",
       "       690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702,\n",
       "       703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715,\n",
       "       716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728,\n",
       "       729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741,\n",
       "       742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754,\n",
       "       755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767,\n",
       "       768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780,\n",
       "       781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793,\n",
       "       794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806,\n",
       "       807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
       "       820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832,\n",
       "       833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845,\n",
       "       846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858,\n",
       "       859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871,\n",
       "       872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884,\n",
       "       885, 886, 887, 888, 889, 890, 891])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passanger_id = np.arange(1, len(predictions) + 1)\n",
    "passanger_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05701197, 0.9815234 , 0.75580287, 0.97204787, 0.07413565,\n",
       "       0.0681882 , 0.23828526, 0.11711147, 0.89393795, 0.9784754 ,\n",
       "       0.6905775 , 0.97732615, 0.07377546, 0.01028379, 0.36300373,\n",
       "       0.8753906 , 0.04339106, 0.19981164, 0.5252084 , 0.7525909 ,\n",
       "       0.05060114, 0.05523799, 0.9113914 , 0.42637715, 0.19293302,\n",
       "       0.12480571, 0.10533528, 0.01470271, 0.9115223 , 0.12220655,\n",
       "       0.3062078 , 0.9901994 , 0.9116349 , 0.0559787 , 0.7863868 ,\n",
       "       0.32528707, 0.10533631, 0.07377546, 0.28653058, 0.5844018 ,\n",
       "       0.3178981 , 0.75665677, 0.10549946, 0.9875815 , 0.4604545 ,\n",
       "       0.12221698, 0.07707734, 0.9116349 , 0.23229979, 0.3889504 ,\n",
       "       0.05867792, 0.07367533, 0.98335534, 0.9869133 , 0.1126862 ,\n",
       "       0.30955073, 0.96371263, 0.2147619 , 0.9907943 , 0.02843964,\n",
       "       0.2841488 , 0.99332917, 0.29401845, 0.1011811 , 0.13922036,\n",
       "       0.5619972 , 0.97457784, 0.07381885, 0.15419503, 0.03260846,\n",
       "       0.09135986, 0.15900606, 0.04058167, 0.11927892, 0.42690524,\n",
       "       0.1766597 , 0.12220655, 0.12221698, 0.9842307 , 0.57530516,\n",
       "       0.07412294, 0.33109325, 0.91160226, 0.45934457, 0.9851407 ,\n",
       "       0.84377944, 0.44601777, 0.12221698, 0.9929338 , 0.1777236 ,\n",
       "       0.32487252, 0.07369703, 0.3044577 , 0.08899103, 0.07445487,\n",
       "       0.12221698, 0.28475225, 0.8294566 , 0.95927054, 0.03737288,\n",
       "       0.5581437 , 0.12220655, 0.07492596, 0.327487  , 0.03229395,\n",
       "       0.3242071 , 0.54217005, 0.12219018, 0.07419709, 0.93886906,\n",
       "       0.23788449, 0.5865549 , 0.07377546, 0.3961971 , 0.7556485 ,\n",
       "       0.07372536, 0.02992912, 0.13818185, 0.5582419 , 0.17079006,\n",
       "       0.03558112, 0.12221698, 0.14202529, 0.9752322 , 0.1008175 ,\n",
       "       0.16738483, 0.06833693, 0.17531498, 0.7905465 , 0.07456488,\n",
       "       0.21580936, 0.07337575, 0.33258644, 0.9869133 , 0.07284082,\n",
       "       0.1049886 , 0.9881574 , 0.32245716, 0.12228157, 0.75742704,\n",
       "       0.54502285, 0.54220307, 0.6404333 , 0.03061278, 0.07597776,\n",
       "       0.07512127, 0.17704692, 0.21019341, 0.08002587, 0.05523799,\n",
       "       0.05539177, 0.9822752 , 0.07413565, 0.09171239, 0.12212759,\n",
       "       0.11314794, 0.91164947, 0.32487252, 0.12225091, 0.00939388,\n",
       "       0.08709984, 0.87503713, 0.17699163, 0.12225091, 0.05867792,\n",
       "       0.8062311 , 0.99261725, 0.1223208 , 0.314156  , 0.42690524,\n",
       "       0.32126543, 0.04339106, 0.6812084 , 0.07372536, 0.29695836,\n",
       "       0.05883616, 0.12201498, 0.92669076, 0.09313286, 0.07740568,\n",
       "       0.06529884, 0.19519539, 0.05680207, 0.85874605, 0.52968657,\n",
       "       0.29538733, 0.94495904, 0.35037363, 0.01751247, 0.07419709,\n",
       "       0.9752322 , 0.07457212, 0.3979898 , 0.94780165, 0.9262409 ,\n",
       "       0.9874514 , 0.06833693, 0.09114505, 0.9116349 , 0.75355864,\n",
       "       0.33109325, 0.00939388, 0.07475694, 0.11204709, 0.07377546,\n",
       "       0.7082809 , 0.14380804, 0.34724215, 0.9116349 , 0.29602182,\n",
       "       0.17507328, 0.8810868 , 0.07345554, 0.09313286, 0.07574843,\n",
       "       0.99734473, 0.75580287, 0.03719218, 0.9942685 , 0.09135986,\n",
       "       0.12221698, 0.07284082, 0.07413565, 0.12220655, 0.29180145,\n",
       "       0.07423103, 0.07687405, 0.07345554, 0.07457212, 0.19829836,\n",
       "       0.9820483 , 0.3236863 , 0.05507655, 0.1708453 , 0.07200073,\n",
       "       0.3622504 , 0.03737288, 0.98629487, 0.07687405, 0.09261557,\n",
       "       0.5865549 , 0.94495904, 0.09135986, 0.07340567, 0.21475531,\n",
       "       0.07263036, 0.75555885, 0.98583204, 0.37183   , 0.03737288,\n",
       "       0.12211913, 0.5547657 , 0.35037363, 0.14421646, 0.2771392 ,\n",
       "       0.88632524, 0.97884035, 0.9920422 , 0.9995992 , 0.96080977,\n",
       "       0.06833693, 0.05680207, 0.21264438, 0.3017934 , 0.9116349 ,\n",
       "       0.0559787 , 0.05867792, 0.07438628, 0.9913311 , 0.98827016,\n",
       "       0.31241605, 0.15719616, 0.9586056 , 0.14885877, 0.9116349 ,\n",
       "       0.9805924 , 0.3289593 , 0.21062413, 0.04339106, 0.41188157,\n",
       "       0.02992912, 0.32402775, 0.12229732, 0.07377546, 0.31413525,\n",
       "       0.21701872, 0.33109325, 0.07371368, 0.05523799, 0.4603195 ,\n",
       "       0.95495504, 0.9838335 , 0.09959015, 0.7573716 , 0.17731293,\n",
       "       0.13922036, 0.32615617, 0.9809109 , 0.3125904 , 0.9854981 ,\n",
       "       0.9116349 , 0.08410689, 0.07061406, 0.9788374 , 0.12221698,\n",
       "       0.94400334, 0.9833612 , 0.9842001 , 0.13647112, 0.9923313 ,\n",
       "       0.96663785, 0.98703885, 0.9546435 , 0.3242071 , 0.0507458 ,\n",
       "       0.7556877 , 0.7545827 , 0.05491559, 0.94995636, 0.99248433,\n",
       "       0.07345554, 0.17731293, 0.8799656 , 0.9705555 , 0.00939388,\n",
       "       0.98697984, 0.07486065, 0.8714669 , 0.613449  , 0.9819492 ,\n",
       "       0.867385  , 0.34801272, 0.0365105 , 0.17432813, 0.9869153 ,\n",
       "       0.12220655, 0.44682664, 0.9869296 , 0.07413565, 0.31033623,\n",
       "       0.94780165, 0.9929338 , 0.09313286, 0.07284082, 0.05523799,\n",
       "       0.75355864, 0.8714669 , 0.67542934, 0.58759165, 0.0738921 ,\n",
       "       0.18087782, 0.31004566, 0.5493821 , 0.08156281, 0.10533528,\n",
       "       0.33109325, 0.9895046 , 0.8714669 , 0.9115223 , 0.9115223 ,\n",
       "       0.02014532, 0.13987516, 0.39730608, 0.07453484, 0.07707734,\n",
       "       0.3214278 , 0.98290837, 0.75259066, 0.9116349 , 0.9647263 ,\n",
       "       0.8865779 , 0.05696825, 0.07377546, 0.06806669, 0.19293302,\n",
       "       0.9822607 , 0.542038  , 0.06067054, 0.28326923, 0.07366531,\n",
       "       0.99316055, 0.54547596, 0.3243331 , 0.9718552 , 0.12220655,\n",
       "       0.04058167, 0.02843964, 0.8714669 , 0.06834129, 0.9753006 ,\n",
       "       0.07065812, 0.07367367, 0.06303511, 0.9815488 , 0.89486593,\n",
       "       0.07367367, 0.5579759 , 0.05060114, 0.07200073, 0.9751416 ,\n",
       "       0.07418545, 0.1777236 , 0.3961971 , 0.14380804, 0.54250395,\n",
       "       0.03828912, 0.07425522, 0.95088047, 0.07366531, 0.19829836,\n",
       "       0.12220655, 0.0685246 , 0.95612985, 0.21062413, 0.07418545,\n",
       "       0.36350477, 0.9496578 , 0.98482877, 0.09313286, 0.52780354,\n",
       "       0.10549946, 0.0303579 , 0.32411742, 0.57719946, 0.05797482,\n",
       "       0.12211913, 0.9869133 , 0.9579857 , 0.06833693, 0.32487252,\n",
       "       0.39541402, 0.67542934, 0.83609796, 0.12210223, 0.31611794,\n",
       "       0.9839795 , 0.65027684, 0.9886987 , 0.00562853, 0.09135986,\n",
       "       0.95219684, 0.07427739, 0.07438628, 0.9752322 , 0.12222043,\n",
       "       0.9659757 , 0.9911367 , 0.35037363, 0.7686117 , 0.33803028,\n",
       "       0.05692883, 0.19291356, 0.36884874, 0.69929475, 0.12221698,\n",
       "       0.21580936, 0.35037363, 0.9894276 , 0.8698049 , 0.06833693,\n",
       "       0.35037363, 0.07413565, 0.2947653 , 0.05523799, 0.12221698,\n",
       "       0.07453484, 0.21062413, 0.35037363, 0.06834217, 0.7686117 ,\n",
       "       0.12211913, 0.0738921 , 0.9670705 , 0.8138919 , 0.54289156,\n",
       "       0.29335257, 0.03828912, 0.13003698, 0.07356368, 0.71470964,\n",
       "       0.02843964, 0.21062413, 0.07413565, 0.3335656 , 0.8909627 ,\n",
       "       0.19829836, 0.9833088 , 0.30003637, 0.32487252, 0.58759165,\n",
       "       0.19291356, 0.07345554, 0.33803028, 0.24055664, 0.07377546,\n",
       "       0.10538472, 0.98380786, 0.12301466, 0.929775  , 0.17704692,\n",
       "       0.12225091, 0.4603195 , 0.91174006, 0.3335656 , 0.9874366 ,\n",
       "       0.13685517, 0.92939496, 0.31396914, 0.37870377, 0.33168054,\n",
       "       0.33260652, 0.12221698, 0.35064858, 0.97641253, 0.17625092,\n",
       "       0.31839994, 0.8698049 , 0.06515487, 0.83609796, 0.3242071 ,\n",
       "       0.99273914, 0.07371368, 0.10533528, 0.96113425, 0.10533631,\n",
       "       0.02992912, 0.8698049 , 0.14051816, 0.07418545, 0.02941039,\n",
       "       0.99310136, 0.10533631, 0.5493821 , 0.5551696 , 0.56116956,\n",
       "       0.98629487, 0.35037363, 0.99640423, 0.12290046, 0.9803119 ,\n",
       "       0.9876609 , 0.17079006, 0.17079006, 0.14792015, 0.6688498 ,\n",
       "       0.35094997, 0.9189257 , 0.19572727, 0.12899637, 0.94381183,\n",
       "       0.39288765, 0.07745852, 0.06832028, 0.2841512 , 0.54221123,\n",
       "       0.35037363, 0.9648247 , 0.09956629, 0.9846272 , 0.3426598 ,\n",
       "       0.06833693, 0.07419709, 0.09349117, 0.12221698, 0.36350477,\n",
       "       0.03627542, 0.07371368, 0.05175973, 0.10533631, 0.32402775,\n",
       "       0.0559787 , 0.94559973, 0.35054386, 0.9116349 , 0.12221698,\n",
       "       0.07451294, 0.8714669 , 0.9725324 , 0.58655834, 0.3243331 ,\n",
       "       0.95325315, 0.9888812 , 0.05060114, 0.26770383, 0.10569956,\n",
       "       0.9834598 , 0.05459495, 0.505762  , 0.07377546, 0.12221698,\n",
       "       0.07450484, 0.98380786, 0.07445487, 0.27523273, 0.03737288,\n",
       "       0.05440122, 0.98252577, 0.07740568, 0.10533528, 0.6725904 ,\n",
       "       0.9542369 , 0.12220655, 0.30276388, 0.07413565, 0.30989206,\n",
       "       0.05091691, 0.3242071 , 0.86680317, 0.9884124 , 0.9906433 ,\n",
       "       0.12488308, 0.12209211, 0.94495904, 0.06833693, 0.07413565,\n",
       "       0.97504175, 0.05656036, 0.6410135 , 0.9898496 , 0.07200073,\n",
       "       0.11927892, 0.32385963, 0.17738774, 0.07369703, 0.07451948,\n",
       "       0.3278033 , 0.022188  , 0.98572844, 0.17731293, 0.06834045,\n",
       "       0.34086588, 0.07453316, 0.3823474 , 0.31461155, 0.17675932,\n",
       "       0.9752322 , 0.3243331 , 0.19437227, 0.08237901, 0.18626787,\n",
       "       0.07369703, 0.9647263 , 0.17675932, 0.13529949, 0.7686117 ,\n",
       "       0.7100936 , 0.07371368, 0.28207818, 0.12215972, 0.75519264,\n",
       "       0.12220655, 0.98046166, 0.07392917, 0.9115659 , 0.45927432,\n",
       "       0.05623684, 0.12220655, 0.17916429, 0.07284082, 0.05861602,\n",
       "       0.75925463, 0.11204709, 0.35138252, 0.07435664, 0.05705108,\n",
       "       0.16392092, 0.07284082, 0.12219018, 0.07413565, 0.9894316 ,\n",
       "       0.94746566, 0.38870052, 0.0559787 , 0.09313286, 0.21062413,\n",
       "       0.07366531, 0.1777236 , 0.54289293, 0.06314792, 0.8984816 ,\n",
       "       0.9112968 , 0.7606669 , 0.0741924 , 0.02843964, 0.04582555,\n",
       "       0.13281438, 0.05867792, 0.07448325, 0.07367367, 0.9955633 ,\n",
       "       0.405339  , 0.8453197 , 0.13529949, 0.32614267, 0.35037363,\n",
       "       0.05507655, 0.07413565, 0.91164947, 0.2753014 , 0.07429512,\n",
       "       0.98972857, 0.35064858, 0.81434613, 0.04459013, 0.07444003,\n",
       "       0.05060114, 0.8719385 , 0.35064858, 0.9817897 , 0.5619972 ,\n",
       "       0.9598025 , 0.31396914, 0.32528707, 0.33102646, 0.05523799,\n",
       "       0.07361534, 0.99316055, 0.75587326, 0.06681804, 0.3236863 ,\n",
       "       0.9905325 , 0.17206782, 0.05523799, 0.05523799, 0.84316814,\n",
       "       0.07401884, 0.987706  , 0.91164577, 0.04751126, 0.61963636,\n",
       "       0.99841166, 0.10386207, 0.21062413, 0.07284082, 0.07284082,\n",
       "       0.356333  , 0.15818793, 0.9749742 , 0.12220655, 0.12220655,\n",
       "       0.31276467, 0.29550973, 0.98703885, 0.08026129, 0.3243331 ,\n",
       "       0.26512775, 0.59144616, 0.9752322 , 0.1761853 , 0.33260652,\n",
       "       0.993184  , 0.5879291 , 0.33109325, 0.17731293, 0.95196617,\n",
       "       0.9529196 , 0.3237759 , 0.07597776, 0.07413565, 0.9920422 ,\n",
       "       0.12290046, 0.07450484, 0.2841488 , 0.98735964, 0.12219018,\n",
       "       0.9805924 , 0.1427444 , 0.31773117, 0.07905652, 0.32622343,\n",
       "       0.18162231, 0.07421366, 0.8698049 , 0.10533528, 0.88044775,\n",
       "       0.07365532, 0.06833693, 0.37536415, 0.06833955, 0.9944945 ,\n",
       "       0.75259066, 0.9895885 , 0.4087127 , 0.5437151 , 0.17507328,\n",
       "       0.17560086, 0.54211915, 0.04339106, 0.5403022 , 0.19266875,\n",
       "       0.06833693, 0.19026795, 0.06529884, 0.13956895, 0.17731293,\n",
       "       0.05523799, 0.97725385, 0.5612469 , 0.2147619 , 0.6355779 ,\n",
       "       0.05523799, 0.97719693, 0.9664029 , 0.46868083, 0.17487577,\n",
       "       0.3236863 , 0.3017934 , 0.54221123, 0.05523799, 0.99107873,\n",
       "       0.17729087, 0.06780563, 0.0559787 , 0.17079006, 0.32487252,\n",
       "       0.31461155, 0.75580287, 0.14345333, 0.07477532, 0.1011811 ,\n",
       "       0.98563075, 0.17936237, 0.3017934 , 0.8750349 , 0.05867792,\n",
       "       0.06850526, 0.13529949, 0.96484596, 0.06833693, 0.99332917,\n",
       "       0.5865549 , 0.95088047, 0.10533631, 0.17720218, 0.07387569,\n",
       "       0.9848496 , 0.07401884, 0.12221698, 0.42690524, 0.13945217,\n",
       "       0.07372536, 0.20178545, 0.9884739 , 0.11277352, 0.12225091,\n",
       "       0.07433501, 0.00939388, 0.11143152, 0.23974699, 0.9813218 ,\n",
       "       0.0567934 , 0.07424525, 0.77007735, 0.99360746, 0.83609796,\n",
       "       0.7771152 , 0.9936824 , 0.35037363, 0.96339196, 0.10533631,\n",
       "       0.03250035, 0.06426577, 0.97725385, 0.06529884, 0.07284082,\n",
       "       0.8714669 , 0.8615645 , 0.46691442, 0.12229732, 0.57961845,\n",
       "       0.17731293, 0.98336756, 0.31594384, 0.07375826, 0.9895858 ,\n",
       "       0.7525909 , 0.07438441, 0.07371368, 0.12220655, 0.9696865 ,\n",
       "       0.9397747 , 0.3242071 , 0.5431155 , 0.09135986, 0.17507328,\n",
       "       0.03481069, 0.07284082, 0.9815844 , 0.4060215 , 0.8535656 ,\n",
       "       0.33260646], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_reshape = np.reshape(a=predictions, newshape=len(predictions))\n",
    "predictions_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_round = np.where(predictions_reshape > 0.5, 1, 0)\n",
    "predictions_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0              1         0\n",
       "1              2         1\n",
       "2              3         1\n",
       "3              4         1\n",
       "4              5         0\n",
       "..           ...       ...\n",
       "886          887         0\n",
       "887          888         1\n",
       "888          889         0\n",
       "889          890         1\n",
       "890          891         0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_by_pid = pd.DataFrame(\n",
    "    data={\"PassengerId\": passanger_id, \"Survived\": predictions_round}\n",
    ")\n",
    "\n",
    "predictions_by_pid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-ml-tfpj-M2nteehU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
