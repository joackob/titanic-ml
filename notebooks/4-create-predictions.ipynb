{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras as kr\n",
    "import pathlib as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/blanc/Documents/GitHub/titanic-ml-tfpj/data/raw/train.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_model_path = pl.Path(\"../models/inference_model.keras\")\n",
    "training_model_path = pl.Path(\"../models/training_model.keras\")\n",
    "titanic_data_test_path = pl.Path(\"../data/raw/train.csv\")\n",
    "\n",
    "inference_model_path.resolve()\n",
    "training_model_path.resolve()\n",
    "titanic_data_test_path.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se deben predecir un total de 891 casos\n"
     ]
    }
   ],
   "source": [
    "titanic_data_test = pd.read_csv(filepath_or_buffer=titanic_data_test_path)\n",
    "titanic_data_test.loc[titanic_data_test[\"Embarked\"].isna(), \"Embarked\"] = \"D\"\n",
    "titanic_data_test = titanic_data_test.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"Pclass\",\n",
    "        \"Sex\",\n",
    "        \"Age\",\n",
    "        \"SibSp\",\n",
    "        \"Parch\",\n",
    "        \"Fare\",\n",
    "        \"Embarked\",\n",
    "    ],\n",
    "]\n",
    "print(\"Se deben predecir un total de {} casos\".format(len(titanic_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se deben predecir un total de 1 casos\n"
     ]
    }
   ],
   "source": [
    "# input_dict = {name: tf.convert_to_tensor(value) for name, value in sample.items()}\n",
    "titanic_dataset = tf.data.Dataset.from_tensors(tensors=dict(titanic_data_test))\n",
    "\n",
    "print(\n",
    "    \"Se deben predecir un total de {} casos\".format(\n",
    "        len(titanic_dataset),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Pclass': <tf.Tensor: shape=(891,), dtype=int64, numpy=\n",
       "  array([3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2,\n",
       "         3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3, 1, 1, 3, 1, 3,\n",
       "         2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3,\n",
       "         1, 3, 3, 3, 1, 3, 3, 3, 1, 1, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3,\n",
       "         1, 3, 3, 3, 3, 3, 3, 2, 1, 3, 2, 3, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 2, 2, 2, 1, 1, 3, 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 1, 3, 3,\n",
       "         3, 1, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3, 3, 1, 3,\n",
       "         3, 1, 2, 3, 3, 2, 3, 2, 3, 1, 3, 1, 3, 3, 2, 2, 3, 2, 1, 1, 3, 3,\n",
       "         3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 2, 3, 1, 3, 2, 1, 2,\n",
       "         3, 2, 3, 3, 1, 3, 2, 3, 2, 3, 1, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3,\n",
       "         2, 3, 3, 1, 3, 2, 1, 2, 3, 3, 1, 3, 3, 3, 1, 1, 1, 2, 3, 3, 1, 1,\n",
       "         3, 2, 3, 3, 1, 1, 1, 3, 2, 1, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3,\n",
       "         3, 3, 2, 3, 1, 1, 2, 3, 3, 1, 3, 1, 1, 1, 3, 3, 3, 2, 3, 1, 1, 1,\n",
       "         2, 1, 1, 1, 2, 3, 2, 3, 2, 2, 1, 1, 3, 3, 2, 2, 3, 1, 3, 2, 3, 1,\n",
       "         3, 1, 1, 3, 1, 3, 1, 1, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1,\n",
       "         3, 3, 3, 3, 1, 2, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 1, 1, 3, 3, 1,\n",
       "         3, 1, 3, 1, 3, 3, 1, 3, 3, 1, 3, 2, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3,\n",
       "         3, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 2, 2,\n",
       "         2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 1, 3, 2, 3, 1, 1, 3, 2, 1, 2,\n",
       "         2, 3, 3, 2, 3, 1, 2, 1, 3, 1, 2, 3, 1, 1, 3, 3, 1, 1, 2, 3, 1, 3,\n",
       "         1, 2, 3, 3, 2, 1, 3, 3, 3, 3, 2, 2, 3, 1, 2, 3, 3, 3, 3, 2, 3, 3,\n",
       "         1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1,\n",
       "         2, 1, 3, 3, 3, 3, 1, 1, 3, 1, 2, 3, 2, 3, 1, 3, 3, 1, 3, 3, 2, 1,\n",
       "         3, 2, 2, 3, 3, 3, 3, 2, 1, 1, 3, 1, 1, 3, 3, 2, 1, 1, 2, 2, 3, 2,\n",
       "         1, 2, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 1,\n",
       "         1, 3, 3, 3, 2, 1, 3, 3, 2, 1, 2, 1, 3, 1, 2, 1, 3, 3, 3, 1, 3, 3,\n",
       "         2, 3, 2, 3, 3, 1, 2, 3, 1, 3, 1, 3, 3, 1, 2, 1, 3, 3, 3, 3, 3, 2,\n",
       "         3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 2, 1, 3, 3, 1, 3, 1, 1, 3, 2, 3, 2,\n",
       "         3, 3, 3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 1,\n",
       "         1, 3, 1, 3, 3, 2, 2, 3, 3, 1, 2, 1, 2, 2, 2, 3, 3, 3, 3, 1, 3, 1,\n",
       "         3, 3, 2, 2, 3, 3, 3, 1, 1, 3, 3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 3, 3,\n",
       "         3, 2, 2, 1, 1, 3, 1, 1, 1, 3, 2, 3, 1, 2, 3, 3, 2, 3, 2, 2, 1, 3,\n",
       "         2, 3, 2, 3, 1, 3, 2, 2, 2, 3, 3, 1, 3, 3, 1, 1, 1, 3, 3, 1, 3, 2,\n",
       "         1, 3, 2, 3, 3, 3, 2, 2, 3, 2, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3,\n",
       "         3, 3, 2, 3, 2, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 2,\n",
       "         3, 1, 3, 2, 1, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1, 3, 2, 1, 3, 3, 2, 3,\n",
       "         3, 1, 3, 2, 3, 3, 1, 3, 1, 3, 3, 3, 3, 2, 3, 1, 3, 2, 3, 3, 3, 1,\n",
       "         3, 3, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 1, 2, 3, 1, 1,\n",
       "         3, 3, 3, 2, 1, 3, 2, 2, 2, 1, 3, 3, 3, 1, 1, 3, 2, 3, 3, 3, 3, 1,\n",
       "         2, 3, 3, 2, 3, 3, 2, 1, 3, 1, 3], dtype=int64)>,\n",
       "  'Sex': <tf.Tensor: shape=(891,), dtype=string, numpy=\n",
       "  array([b'male', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'female', b'female',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'female',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'female', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'female', b'female',\n",
       "         b'female', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'female', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'female', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'female', b'female', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'female', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'female',\n",
       "         b'female', b'male', b'male', b'male', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'female', b'female', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'male', b'female', b'male', b'male', b'male', b'female',\n",
       "         b'female', b'male', b'female', b'male', b'female', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'female', b'male', b'male', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
       "         b'female', b'female', b'female', b'female', b'female', b'male',\n",
       "         b'female', b'male', b'male', b'male', b'female', b'female',\n",
       "         b'male', b'female', b'female', b'male', b'male', b'male', b'male',\n",
       "         b'female', b'male', b'male', b'female', b'female', b'male',\n",
       "         b'male', b'male', b'female', b'female', b'male', b'female',\n",
       "         b'male', b'male', b'female', b'male', b'female', b'female',\n",
       "         b'male', b'male'], dtype=object)>,\n",
       "  'Age': <tf.Tensor: shape=(891,), dtype=float64, numpy=\n",
       "  array([22.  , 38.  , 26.  , 35.  , 35.  ,   nan, 54.  ,  2.  , 27.  ,\n",
       "         14.  ,  4.  , 58.  , 20.  , 39.  , 14.  , 55.  ,  2.  ,   nan,\n",
       "         31.  ,   nan, 35.  , 34.  , 15.  , 28.  ,  8.  , 38.  ,   nan,\n",
       "         19.  ,   nan,   nan, 40.  ,   nan,   nan, 66.  , 28.  , 42.  ,\n",
       "           nan, 21.  , 18.  , 14.  , 40.  , 27.  ,   nan,  3.  , 19.  ,\n",
       "           nan,   nan,   nan,   nan, 18.  ,  7.  , 21.  , 49.  , 29.  ,\n",
       "         65.  ,   nan, 21.  , 28.5 ,  5.  , 11.  , 22.  , 38.  , 45.  ,\n",
       "          4.  ,   nan,   nan, 29.  , 19.  , 17.  , 26.  , 32.  , 16.  ,\n",
       "         21.  , 26.  , 32.  , 25.  ,   nan,   nan,  0.83, 30.  , 22.  ,\n",
       "         29.  ,   nan, 28.  , 17.  , 33.  , 16.  ,   nan, 23.  , 24.  ,\n",
       "         29.  , 20.  , 46.  , 26.  , 59.  ,   nan, 71.  , 23.  , 34.  ,\n",
       "         34.  , 28.  ,   nan, 21.  , 33.  , 37.  , 28.  , 21.  ,   nan,\n",
       "         38.  ,   nan, 47.  , 14.5 , 22.  , 20.  , 17.  , 21.  , 70.5 ,\n",
       "         29.  , 24.  ,  2.  , 21.  ,   nan, 32.5 , 32.5 , 54.  , 12.  ,\n",
       "           nan, 24.  ,   nan, 45.  , 33.  , 20.  , 47.  , 29.  , 25.  ,\n",
       "         23.  , 19.  , 37.  , 16.  , 24.  ,   nan, 22.  , 24.  , 19.  ,\n",
       "         18.  , 19.  , 27.  ,  9.  , 36.5 , 42.  , 51.  , 22.  , 55.5 ,\n",
       "         40.5 ,   nan, 51.  , 16.  , 30.  ,   nan,   nan, 44.  , 40.  ,\n",
       "         26.  , 17.  ,  1.  ,  9.  ,   nan, 45.  ,   nan, 28.  , 61.  ,\n",
       "          4.  ,  1.  , 21.  , 56.  , 18.  ,   nan, 50.  , 30.  , 36.  ,\n",
       "           nan,   nan,  9.  ,  1.  ,  4.  ,   nan,   nan, 45.  , 40.  ,\n",
       "         36.  , 32.  , 19.  , 19.  ,  3.  , 44.  , 58.  ,   nan, 42.  ,\n",
       "           nan, 24.  , 28.  ,   nan, 34.  , 45.5 , 18.  ,  2.  , 32.  ,\n",
       "         26.  , 16.  , 40.  , 24.  , 35.  , 22.  , 30.  ,   nan, 31.  ,\n",
       "         27.  , 42.  , 32.  , 30.  , 16.  , 27.  , 51.  ,   nan, 38.  ,\n",
       "         22.  , 19.  , 20.5 , 18.  ,   nan, 35.  , 29.  , 59.  ,  5.  ,\n",
       "         24.  ,   nan, 44.  ,  8.  , 19.  , 33.  ,   nan,   nan, 29.  ,\n",
       "         22.  , 30.  , 44.  , 25.  , 24.  , 37.  , 54.  ,   nan, 29.  ,\n",
       "         62.  , 30.  , 41.  , 29.  ,   nan, 30.  , 35.  , 50.  ,   nan,\n",
       "          3.  , 52.  , 40.  ,   nan, 36.  , 16.  , 25.  , 58.  , 35.  ,\n",
       "           nan, 25.  , 41.  , 37.  ,   nan, 63.  , 45.  ,   nan,  7.  ,\n",
       "         35.  , 65.  , 28.  , 16.  , 19.  ,   nan, 33.  , 30.  , 22.  ,\n",
       "         42.  , 22.  , 26.  , 19.  , 36.  , 24.  , 24.  ,   nan, 23.5 ,\n",
       "          2.  ,   nan, 50.  ,   nan,   nan, 19.  ,   nan,   nan,  0.92,\n",
       "           nan, 17.  , 30.  , 30.  , 24.  , 18.  , 26.  , 28.  , 43.  ,\n",
       "         26.  , 24.  , 54.  , 31.  , 40.  , 22.  , 27.  , 30.  , 22.  ,\n",
       "           nan, 36.  , 61.  , 36.  , 31.  , 16.  ,   nan, 45.5 , 38.  ,\n",
       "         16.  ,   nan,   nan, 29.  , 41.  , 45.  , 45.  ,  2.  , 24.  ,\n",
       "         28.  , 25.  , 36.  , 24.  , 40.  ,   nan,  3.  , 42.  , 23.  ,\n",
       "           nan, 15.  , 25.  ,   nan, 28.  , 22.  , 38.  ,   nan,   nan,\n",
       "         40.  , 29.  , 45.  , 35.  ,   nan, 30.  , 60.  ,   nan,   nan,\n",
       "         24.  , 25.  , 18.  , 19.  , 22.  ,  3.  ,   nan, 22.  , 27.  ,\n",
       "         20.  , 19.  , 42.  ,  1.  , 32.  , 35.  ,   nan, 18.  ,  1.  ,\n",
       "         36.  ,   nan, 17.  , 36.  , 21.  , 28.  , 23.  , 24.  , 22.  ,\n",
       "         31.  , 46.  , 23.  , 28.  , 39.  , 26.  , 21.  , 28.  , 20.  ,\n",
       "         34.  , 51.  ,  3.  , 21.  ,   nan,   nan,   nan, 33.  ,   nan,\n",
       "         44.  ,   nan, 34.  , 18.  , 30.  , 10.  ,   nan, 21.  , 29.  ,\n",
       "         28.  , 18.  ,   nan, 28.  , 19.  ,   nan, 32.  , 28.  ,   nan,\n",
       "         42.  , 17.  , 50.  , 14.  , 21.  , 24.  , 64.  , 31.  , 45.  ,\n",
       "         20.  , 25.  , 28.  ,   nan,  4.  , 13.  , 34.  ,  5.  , 52.  ,\n",
       "         36.  ,   nan, 30.  , 49.  ,   nan, 29.  , 65.  ,   nan, 50.  ,\n",
       "           nan, 48.  , 34.  , 47.  , 48.  ,   nan, 38.  ,   nan, 56.  ,\n",
       "           nan,  0.75,   nan, 38.  , 33.  , 23.  , 22.  ,   nan, 34.  ,\n",
       "         29.  , 22.  ,  2.  ,  9.  ,   nan, 50.  , 63.  , 25.  ,   nan,\n",
       "         35.  , 58.  , 30.  ,  9.  ,   nan, 21.  , 55.  , 71.  , 21.  ,\n",
       "           nan, 54.  ,   nan, 25.  , 24.  , 17.  , 21.  ,   nan, 37.  ,\n",
       "         16.  , 18.  , 33.  ,   nan, 28.  , 26.  , 29.  ,   nan, 36.  ,\n",
       "         54.  , 24.  , 47.  , 34.  ,   nan, 36.  , 32.  , 30.  , 22.  ,\n",
       "           nan, 44.  ,   nan, 40.5 , 50.  ,   nan, 39.  , 23.  ,  2.  ,\n",
       "           nan, 17.  ,   nan, 30.  ,  7.  , 45.  , 30.  ,   nan, 22.  ,\n",
       "         36.  ,  9.  , 11.  , 32.  , 50.  , 64.  , 19.  ,   nan, 33.  ,\n",
       "          8.  , 17.  , 27.  ,   nan, 22.  , 22.  , 62.  , 48.  ,   nan,\n",
       "         39.  , 36.  ,   nan, 40.  , 28.  ,   nan,   nan, 24.  , 19.  ,\n",
       "         29.  ,   nan, 32.  , 62.  , 53.  , 36.  ,   nan, 16.  , 19.  ,\n",
       "         34.  , 39.  ,   nan, 32.  , 25.  , 39.  , 54.  , 36.  ,   nan,\n",
       "         18.  , 47.  , 60.  , 22.  ,   nan, 35.  , 52.  , 47.  ,   nan,\n",
       "         37.  , 36.  ,   nan, 49.  ,   nan, 49.  , 24.  ,   nan,   nan,\n",
       "         44.  , 35.  , 36.  , 30.  , 27.  , 22.  , 40.  , 39.  ,   nan,\n",
       "           nan,   nan, 35.  , 24.  , 34.  , 26.  ,  4.  , 26.  , 27.  ,\n",
       "         42.  , 20.  , 21.  , 21.  , 61.  , 57.  , 21.  , 26.  ,   nan,\n",
       "         80.  , 51.  , 32.  ,   nan,  9.  , 28.  , 32.  , 31.  , 41.  ,\n",
       "           nan, 20.  , 24.  ,  2.  ,   nan,  0.75, 48.  , 19.  , 56.  ,\n",
       "           nan, 23.  ,   nan, 18.  , 21.  ,   nan, 18.  , 24.  ,   nan,\n",
       "         32.  , 23.  , 58.  , 50.  , 40.  , 47.  , 36.  , 20.  , 32.  ,\n",
       "         25.  ,   nan, 43.  ,   nan, 40.  , 31.  , 70.  , 31.  ,   nan,\n",
       "         18.  , 24.5 , 18.  , 43.  , 36.  ,   nan, 27.  , 20.  , 14.  ,\n",
       "         60.  , 25.  , 14.  , 19.  , 18.  , 15.  , 31.  ,  4.  ,   nan,\n",
       "         25.  , 60.  , 52.  , 44.  ,   nan, 49.  , 42.  , 18.  , 35.  ,\n",
       "         18.  , 25.  , 26.  , 39.  , 45.  , 42.  , 22.  ,   nan, 24.  ,\n",
       "           nan, 48.  , 29.  , 52.  , 19.  , 38.  , 27.  ,   nan, 33.  ,\n",
       "          6.  , 17.  , 34.  , 50.  , 27.  , 20.  , 30.  ,   nan, 25.  ,\n",
       "         25.  , 29.  , 11.  ,   nan, 23.  , 23.  , 28.5 , 48.  , 35.  ,\n",
       "           nan,   nan,   nan, 36.  , 21.  , 24.  , 31.  , 70.  , 16.  ,\n",
       "         30.  , 19.  , 31.  ,  4.  ,  6.  , 33.  , 23.  , 48.  ,  0.67,\n",
       "         28.  , 18.  , 34.  , 33.  ,   nan, 41.  , 20.  , 36.  , 16.  ,\n",
       "         51.  ,   nan, 30.5 ,   nan, 32.  , 24.  , 48.  , 57.  ,   nan,\n",
       "         54.  , 18.  ,   nan,  5.  ,   nan, 43.  , 13.  , 17.  , 29.  ,\n",
       "           nan, 25.  , 25.  , 18.  ,  8.  ,  1.  , 46.  ,   nan, 16.  ,\n",
       "           nan,   nan, 25.  , 39.  , 49.  , 31.  , 30.  , 30.  , 34.  ,\n",
       "         31.  , 11.  ,  0.42, 27.  , 31.  , 39.  , 18.  , 39.  , 33.  ,\n",
       "         26.  , 39.  , 35.  ,  6.  , 30.5 ,   nan, 23.  , 31.  , 43.  ,\n",
       "         10.  , 52.  , 27.  , 38.  , 27.  ,  2.  ,   nan,   nan,  1.  ,\n",
       "           nan, 62.  , 15.  ,  0.83,   nan, 23.  , 18.  , 39.  , 21.  ,\n",
       "           nan, 32.  ,   nan, 20.  , 16.  , 30.  , 34.5 , 17.  , 42.  ,\n",
       "           nan, 35.  , 28.  ,   nan,  4.  , 74.  ,  9.  , 16.  , 44.  ,\n",
       "         18.  , 45.  , 51.  , 24.  ,   nan, 41.  , 21.  , 48.  ,   nan,\n",
       "         24.  , 42.  , 27.  , 31.  ,   nan,  4.  , 26.  , 47.  , 33.  ,\n",
       "         47.  , 28.  , 15.  , 20.  , 19.  ,   nan, 56.  , 25.  , 33.  ,\n",
       "         22.  , 28.  , 25.  , 39.  , 27.  , 19.  ,   nan, 26.  , 32.  ])>,\n",
       "  'SibSp': <tf.Tensor: shape=(891,), dtype=int64, numpy=\n",
       "  array([1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0,\n",
       "         0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1,\n",
       "         0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0, 0, 1, 3, 0, 1,\n",
       "         0, 0, 4, 2, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0,\n",
       "         3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
       "         0, 1, 0, 1, 0, 0, 0, 1, 0, 4, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 4, 1, 0, 0, 1,\n",
       "         3, 0, 0, 0, 8, 0, 4, 2, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 8, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "         0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0,\n",
       "         0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 8, 0, 0, 0, 1, 0,\n",
       "         2, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "         3, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0, 0, 0, 1, 0, 2, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 5, 0, 0, 0,\n",
       "         1, 3, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 1, 1, 0, 1, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "         1, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1,\n",
       "         0, 1, 0, 0, 3, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "         2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 5, 1, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "         3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0,\n",
       "         1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 4, 1, 0, 0, 0,\n",
       "         8, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 4,\n",
       "         0, 0, 0, 1, 0, 3, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 1, 4, 0, 1, 0, 1, 0, 1, 0,\n",
       "         0, 0, 2, 1, 0, 8, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)>,\n",
       "  'Parch': <tf.Tensor: shape=(891,), dtype=int64, numpy=\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 1,\n",
       "         0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
       "         2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 2,\n",
       "         0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 1, 4, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "         1, 0, 0, 0, 2, 0, 2, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 1, 0,\n",
       "         0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "         0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2,\n",
       "         0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 4, 0,\n",
       "         1, 0, 0, 0, 0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "         2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 1, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1,\n",
       "         2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 0, 2,\n",
       "         1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1,\n",
       "         5, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0,\n",
       "         0, 2, 1, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0,\n",
       "         0, 0, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "         2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "         0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0,\n",
       "         3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0], dtype=int64)>,\n",
       "  'Fare': <tf.Tensor: shape=(891,), dtype=float64, numpy=\n",
       "  array([  7.25  ,  71.2833,   7.925 ,  53.1   ,   8.05  ,   8.4583,\n",
       "          51.8625,  21.075 ,  11.1333,  30.0708,  16.7   ,  26.55  ,\n",
       "           8.05  ,  31.275 ,   7.8542,  16.    ,  29.125 ,  13.    ,\n",
       "          18.    ,   7.225 ,  26.    ,  13.    ,   8.0292,  35.5   ,\n",
       "          21.075 ,  31.3875,   7.225 , 263.    ,   7.8792,   7.8958,\n",
       "          27.7208, 146.5208,   7.75  ,  10.5   ,  82.1708,  52.    ,\n",
       "           7.2292,   8.05  ,  18.    ,  11.2417,   9.475 ,  21.    ,\n",
       "           7.8958,  41.5792,   7.8792,   8.05  ,  15.5   ,   7.75  ,\n",
       "          21.6792,  17.8   ,  39.6875,   7.8   ,  76.7292,  26.    ,\n",
       "          61.9792,  35.5   ,  10.5   ,   7.2292,  27.75  ,  46.9   ,\n",
       "           7.2292,  80.    ,  83.475 ,  27.9   ,  27.7208,  15.2458,\n",
       "          10.5   ,   8.1583,   7.925 ,   8.6625,  10.5   ,  46.9   ,\n",
       "          73.5   ,  14.4542,  56.4958,   7.65  ,   7.8958,   8.05  ,\n",
       "          29.    ,  12.475 ,   9.    ,   9.5   ,   7.7875,  47.1   ,\n",
       "          10.5   ,  15.85  ,  34.375 ,   8.05  , 263.    ,   8.05  ,\n",
       "           8.05  ,   7.8542,  61.175 ,  20.575 ,   7.25  ,   8.05  ,\n",
       "          34.6542,  63.3583,  23.    ,  26.    ,   7.8958,   7.8958,\n",
       "          77.2875,   8.6542,   7.925 ,   7.8958,   7.65  ,   7.775 ,\n",
       "           7.8958,  24.15  ,  52.    ,  14.4542,   8.05  ,   9.825 ,\n",
       "          14.4583,   7.925 ,   7.75  ,  21.    , 247.5208,  31.275 ,\n",
       "          73.5   ,   8.05  ,  30.0708,  13.    ,  77.2875,  11.2417,\n",
       "           7.75  ,   7.1417,  22.3583,   6.975 ,   7.8958,   7.05  ,\n",
       "          14.5   ,  26.    ,  13.    ,  15.0458,  26.2833,  53.1   ,\n",
       "           9.2167,  79.2   ,  15.2458,   7.75  ,  15.85  ,   6.75  ,\n",
       "          11.5   ,  36.75  ,   7.7958,  34.375 ,  26.    ,  13.    ,\n",
       "          12.525 ,  66.6   ,   8.05  ,  14.5   ,   7.3125,  61.3792,\n",
       "           7.7333,   8.05  ,   8.6625,  69.55  ,  16.1   ,  15.75  ,\n",
       "           7.775 ,   8.6625,  39.6875,  20.525 ,  55.    ,  27.9   ,\n",
       "          25.925 ,  56.4958,  33.5   ,  29.125 ,  11.1333,   7.925 ,\n",
       "          30.6958,   7.8542,  25.4667,  28.7125,  13.    ,   0.    ,\n",
       "          69.55  ,  15.05  ,  31.3875,  39.    ,  22.025 ,  50.    ,\n",
       "          15.5   ,  26.55  ,  15.5   ,   7.8958,  13.    ,  13.    ,\n",
       "           7.8542,  26.    ,  27.7208, 146.5208,   7.75  ,   8.4042,\n",
       "           7.75  ,  13.    ,   9.5   ,  69.55  ,   6.4958,   7.225 ,\n",
       "           8.05  ,  10.4625,  15.85  ,  18.7875,   7.75  ,  31.    ,\n",
       "           7.05  ,  21.    ,   7.25  ,  13.    ,   7.75  , 113.275 ,\n",
       "           7.925 ,  27.    ,  76.2917,  10.5   ,   8.05  ,  13.    ,\n",
       "           8.05  ,   7.8958,  90.    ,   9.35  ,  10.5   ,   7.25  ,\n",
       "          13.    ,  25.4667,  83.475 ,   7.775 ,  13.5   ,  31.3875,\n",
       "          10.5   ,   7.55  ,  26.    ,  26.25  ,  10.5   ,  12.275 ,\n",
       "          14.4542,  15.5   ,  10.5   ,   7.125 ,   7.225 ,  90.    ,\n",
       "           7.775 ,  14.5   ,  52.5542,  26.    ,   7.25  ,  10.4625,\n",
       "          26.55  ,  16.1   ,  20.2125,  15.2458,  79.2   ,  86.5   ,\n",
       "         512.3292,  26.    ,   7.75  ,  31.3875,  79.65  ,   0.    ,\n",
       "           7.75  ,  10.5   ,  39.6875,   7.775 , 153.4625, 135.6333,\n",
       "          31.    ,   0.    ,  19.5   ,  29.7   ,   7.75  ,  77.9583,\n",
       "           7.75  ,   0.    ,  29.125 ,  20.25  ,   7.75  ,   7.8542,\n",
       "           9.5   ,   8.05  ,  26.    ,   8.6625,   9.5   ,   7.8958,\n",
       "          13.    ,   7.75  ,  78.85  ,  91.0792,  12.875 ,   8.85  ,\n",
       "           7.8958,  27.7208,   7.2292, 151.55  ,  30.5   , 247.5208,\n",
       "           7.75  ,  23.25  ,   0.    ,  12.35  ,   8.05  , 151.55  ,\n",
       "         110.8833, 108.9   ,  24.    ,  56.9292,  83.1583, 262.375 ,\n",
       "          26.    ,   7.8958,  26.25  ,   7.8542,  26.    ,  14.    ,\n",
       "         164.8667, 134.5   ,   7.25  ,   7.8958,  12.35  ,  29.    ,\n",
       "          69.55  , 135.6333,   6.2375,  13.    ,  20.525 ,  57.9792,\n",
       "          23.25  ,  28.5   , 153.4625,  18.    , 133.65  ,   7.8958,\n",
       "          66.6   , 134.5   ,   8.05  ,  35.5   ,  26.    , 263.    ,\n",
       "          13.    ,  13.    ,  13.    ,  13.    ,  13.    ,  16.1   ,\n",
       "          15.9   ,   8.6625,   9.225 ,  35.    ,   7.2292,  17.8   ,\n",
       "           7.225 ,   9.5   ,  55.    ,  13.    ,   7.8792,   7.8792,\n",
       "          27.9   ,  27.7208,  14.4542,   7.05  ,  15.5   ,   7.25  ,\n",
       "          75.25  ,   7.2292,   7.75  ,  69.3   ,  55.4417,   6.4958,\n",
       "           8.05  , 135.6333,  21.075 ,  82.1708,   7.25  , 211.5   ,\n",
       "           4.0125,   7.775 , 227.525 ,  15.7417,   7.925 ,  52.    ,\n",
       "           7.8958,  73.5   ,  46.9   ,  13.    ,   7.7292,  12.    ,\n",
       "         120.    ,   7.7958,   7.925 , 113.275 ,  16.7   ,   7.7958,\n",
       "           7.8542,  26.    ,  10.5   ,  12.65  ,   7.925 ,   8.05  ,\n",
       "           9.825 ,  15.85  ,   8.6625,  21.    ,   7.75  ,  18.75  ,\n",
       "           7.775 ,  25.4667,   7.8958,   6.8583,  90.    ,   0.    ,\n",
       "           7.925 ,   8.05  ,  32.5   ,  13.    ,  13.    ,  24.15  ,\n",
       "           7.8958,   7.7333,   7.875 ,  14.4   ,  20.2125,   7.25  ,\n",
       "          26.    ,  26.    ,   7.75  ,   8.05  ,  26.55  ,  16.1   ,\n",
       "          26.    ,   7.125 ,  55.9   , 120.    ,  34.375 ,  18.75  ,\n",
       "         263.    ,  10.5   ,  26.25  ,   9.5   ,   7.775 ,  13.    ,\n",
       "           8.1125,  81.8583,  19.5   ,  26.55  ,  19.2583,  30.5   ,\n",
       "          27.75  ,  19.9667,  27.75  ,  89.1042,   8.05  ,   7.8958,\n",
       "          26.55  ,  51.8625,  10.5   ,   7.75  ,  26.55  ,   8.05  ,\n",
       "          38.5   ,  13.    ,   8.05  ,   7.05  ,   0.    ,  26.55  ,\n",
       "           7.725 ,  19.2583,   7.25  ,   8.6625,  27.75  ,  13.7917,\n",
       "           9.8375,  52.    ,  21.    ,   7.0458,   7.5208,  12.2875,\n",
       "          46.9   ,   0.    ,   8.05  ,   9.5875,  91.0792,  25.4667,\n",
       "          90.    ,  29.7   ,   8.05  ,  15.9   ,  19.9667,   7.25  ,\n",
       "          30.5   ,  49.5042,   8.05  ,  14.4583,  78.2667,  15.1   ,\n",
       "         151.55  ,   7.7958,   8.6625,   7.75  ,   7.6292,   9.5875,\n",
       "          86.5   , 108.9   ,  26.    ,  26.55  ,  22.525 ,  56.4958,\n",
       "           7.75  ,   8.05  ,  26.2875,  59.4   ,   7.4958,  34.0208,\n",
       "          10.5   ,  24.15  ,  26.    ,   7.8958,  93.5   ,   7.8958,\n",
       "           7.225 ,  57.9792,   7.2292,   7.75  ,  10.5   , 221.7792,\n",
       "           7.925 ,  11.5   ,  26.    ,   7.2292,   7.2292,  22.3583,\n",
       "           8.6625,  26.25  ,  26.55  , 106.425 ,  14.5   ,  49.5   ,\n",
       "          71.    ,  31.275 ,  31.275 ,  26.    , 106.425 ,  26.    ,\n",
       "          26.    ,  13.8625,  20.525 ,  36.75  , 110.8833,  26.    ,\n",
       "           7.8292,   7.225 ,   7.775 ,  26.55  ,  39.6   , 227.525 ,\n",
       "          79.65  ,  17.4   ,   7.75  ,   7.8958,  13.5   ,   8.05  ,\n",
       "           8.05  ,  24.15  ,   7.8958,  21.075 ,   7.2292,   7.8542,\n",
       "          10.5   ,  51.4792,  26.3875,   7.75  ,   8.05  ,  14.5   ,\n",
       "          13.    ,  55.9   ,  14.4583,   7.925 ,  30.    , 110.8833,\n",
       "          26.    ,  40.125 ,   8.7125,  79.65  ,  15.    ,  79.2   ,\n",
       "           8.05  ,   8.05  ,   7.125 ,  78.2667,   7.25  ,   7.75  ,\n",
       "          26.    ,  24.15  ,  33.    ,   0.    ,   7.225 ,  56.9292,\n",
       "          27.    ,   7.8958,  42.4   ,   8.05  ,  26.55  ,  15.55  ,\n",
       "           7.8958,  30.5   ,  41.5792, 153.4625,  31.275 ,   7.05  ,\n",
       "          15.5   ,   7.75  ,   8.05  ,  65.    ,  14.4   ,  16.1   ,\n",
       "          39.    ,  10.5   ,  14.4542,  52.5542,  15.7417,   7.8542,\n",
       "          16.1   ,  32.3208,  12.35  ,  77.9583,   7.8958,   7.7333,\n",
       "          30.    ,   7.0542,  30.5   ,   0.    ,  27.9   ,  13.    ,\n",
       "           7.925 ,  26.25  ,  39.6875,  16.1   ,   7.8542,  69.3   ,\n",
       "          27.9   ,  56.4958,  19.2583,  76.7292,   7.8958,  35.5   ,\n",
       "           7.55  ,   7.55  ,   7.8958,  23.    ,   8.4333,   7.8292,\n",
       "           6.75  ,  73.5   ,   7.8958,  15.5   ,  13.    , 113.275 ,\n",
       "         133.65  ,   7.225 ,  25.5875,   7.4958,   7.925 ,  73.5   ,\n",
       "          13.    ,   7.775 ,   8.05  ,  52.    ,  39.    ,  52.    ,\n",
       "          10.5   ,  13.    ,   0.    ,   7.775 ,   8.05  ,   9.8417,\n",
       "          46.9   , 512.3292,   8.1375,  76.7292,   9.225 ,  46.9   ,\n",
       "          39.    ,  41.5792,  39.6875,  10.1708,   7.7958, 211.3375,\n",
       "          57.    ,  13.4167,  56.4958,   7.225 ,  26.55  ,  13.5   ,\n",
       "           8.05  ,   7.7333, 110.8833,   7.65  , 227.525 ,  26.2875,\n",
       "          14.4542,   7.7417,   7.8542,  26.    ,  13.5   ,  26.2875,\n",
       "         151.55  ,  15.2458,  49.5042,  26.55  ,  52.    ,   9.4833,\n",
       "          13.    ,   7.65  , 227.525 ,  10.5   ,  15.5   ,   7.775 ,\n",
       "          33.    ,   7.0542,  13.    ,  13.    ,  53.1   ,   8.6625,\n",
       "          21.    ,   7.7375,  26.    ,   7.925 , 211.3375,  18.7875,\n",
       "           0.    ,  13.    ,  13.    ,  16.1   ,  34.375 , 512.3292,\n",
       "           7.8958,   7.8958,  30.    ,  78.85  , 262.375 ,  16.1   ,\n",
       "           7.925 ,  71.    ,  20.25  ,  13.    ,  53.1   ,   7.75  ,\n",
       "          23.    ,  12.475 ,   9.5   ,   7.8958,  65.    ,  14.5   ,\n",
       "           7.7958,  11.5   ,   8.05  ,  86.5   ,  14.5   ,   7.125 ,\n",
       "           7.2292, 120.    ,   7.775 ,  77.9583,  39.6   ,   7.75  ,\n",
       "          24.15  ,   8.3625,   9.5   ,   7.8542,  10.5   ,   7.225 ,\n",
       "          23.    ,   7.75  ,   7.75  ,  12.475 ,   7.7375, 211.3375,\n",
       "           7.2292,  57.    ,  30.    ,  23.45  ,   7.05  ,   7.25  ,\n",
       "           7.4958,  29.125 ,  20.575 ,  79.2   ,   7.75  ,  26.    ,\n",
       "          69.55  ,  30.6958,   7.8958,  13.    ,  25.9292,   8.6833,\n",
       "           7.2292,  24.15  ,  13.    ,  26.25  , 120.    ,   8.5167,\n",
       "           6.975 ,   7.775 ,   0.    ,   7.775 ,  13.    ,  53.1   ,\n",
       "           7.8875,  24.15  ,  10.5   ,  31.275 ,   8.05  ,   0.    ,\n",
       "           7.925 ,  37.0042,   6.45  ,  27.9   ,  93.5   ,   8.6625,\n",
       "           0.    ,  12.475 ,  39.6875,   6.95  ,  56.4958,  37.0042,\n",
       "           7.75  ,  80.    ,  14.4542,  18.75  ,   7.2292,   7.8542,\n",
       "           8.3   ,  83.1583,   8.6625,   8.05  ,  56.4958,  29.7   ,\n",
       "           7.925 ,  10.5   ,  31.    ,   6.4375,   8.6625,   7.55  ,\n",
       "          69.55  ,   7.8958,  33.    ,  89.1042,  31.275 ,   7.775 ,\n",
       "          15.2458,  39.4   ,  26.    ,   9.35  , 164.8667,  26.55  ,\n",
       "          19.2583,   7.2292,  14.1083,  11.5   ,  25.9292,  69.55  ,\n",
       "          13.    ,  13.    ,  13.8583,  50.4958,   9.5   ,  11.1333,\n",
       "           7.8958,  52.5542,   5.    ,   9.    ,  24.    ,   7.225 ,\n",
       "           9.8458,   7.8958,   7.8958,  83.1583,  26.    ,   7.8958,\n",
       "          10.5167,  10.5   ,   7.05  ,  29.125 ,  13.    ,  30.    ,\n",
       "          23.45  ,  30.    ,   7.75  ])>,\n",
       "  'Embarked': <tf.Tensor: shape=(891,), dtype=string, numpy=\n",
       "  array([b'S', b'C', b'S', b'S', b'S', b'Q', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'C', b'S', b'Q', b'S', b'C', b'C', b'Q',\n",
       "         b'S', b'C', b'S', b'C', b'S', b'S', b'C', b'S', b'S', b'C', b'C',\n",
       "         b'Q', b'S', b'Q', b'Q', b'C', b'S', b'S', b'S', b'C', b'S', b'C',\n",
       "         b'S', b'S', b'C', b'S', b'S', b'C', b'D', b'S', b'S', b'C', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'C', b'S', b'S', b'C', b'S', b'Q', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'C', b'S', b'S', b'C', b'Q', b'S', b'C', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'C', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'C', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'C', b'S',\n",
       "         b'S', b'C', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'Q', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'Q',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'Q', b'C', b'S', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'Q',\n",
       "         b'S', b'S', b'C', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'C', b'C', b'S', b'C', b'S', b'Q', b'S', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'Q',\n",
       "         b'S', b'S', b'S', b'Q', b'S', b'Q', b'S', b'S', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'Q', b'S', b'C', b'C', b'S', b'S', b'C', b'C',\n",
       "         b'S', b'S', b'C', b'Q', b'Q', b'S', b'Q', b'S', b'S', b'C', b'C',\n",
       "         b'C', b'C', b'C', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S', b'S', b'C',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'C', b'S', b'S', b'S', b'Q', b'Q', b'S', b'C', b'C',\n",
       "         b'S', b'Q', b'S', b'C', b'C', b'Q', b'C', b'C', b'S', b'S', b'C',\n",
       "         b'S', b'C', b'S', b'C', b'C', b'S', b'C', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'Q', b'C', b'S', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'C', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'C', b'C', b'S', b'C', b'S', b'S', b'S', b'Q', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'Q', b'C', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'C', b'S', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'Q', b'S', b'S', b'S', b'S', b'C', b'C', b'C', b'Q', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'C', b'C', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'C', b'S', b'Q', b'C', b'S', b'S', b'C', b'C', b'S', b'S', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'C', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'S', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'C', b'C', b'S', b'S', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'C', b'S', b'C', b'S', b'S', b'S', b'Q',\n",
       "         b'S', b'S', b'Q', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'C', b'S', b'C', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'Q', b'Q', b'S', b'S', b'Q', b'S', b'C',\n",
       "         b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'Q', b'C',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'C', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'Q', b'C', b'S', b'C', b'S', b'C', b'Q',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'C', b'S', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'Q', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'C', b'Q', b'Q', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'Q', b'S', b'Q', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'C', b'Q', b'S',\n",
       "         b'S', b'C', b'S', b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'Q', b'S', b'C', b'Q', b'D', b'C', b'S', b'C', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'C', b'S', b'S', b'C', b'C', b'S', b'S', b'S',\n",
       "         b'C', b'S', b'C', b'S', b'S', b'C', b'S', b'S', b'S', b'S', b'S',\n",
       "         b'C', b'C', b'S', b'S', b'S', b'S', b'S', b'S', b'C', b'S', b'S',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'C', b'C', b'S', b'S', b'S', b'C',\n",
       "         b'S', b'S', b'S', b'S', b'S', b'Q', b'S', b'S', b'S', b'C', b'Q'],\n",
       "        dtype=object)>}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(titanic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = kr.models.load_model(filepath=inference_model_path)\n",
    "training_model = kr.models.load_model(filepath=training_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pclass': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([3], dtype=int64)>,\n",
       " 'Sex': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'female'], dtype=object)>,\n",
       " 'Age': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([26.])>,\n",
       " 'SibSp': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0], dtype=int64)>,\n",
       " 'Parch': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0], dtype=int64)>,\n",
       " 'Fare': <tf.Tensor: shape=(1,), dtype=float64, numpy=array([7.925])>,\n",
       " 'Embarked': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'S'], dtype=object)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = titanic_data_test.sample(n=1)\n",
    "input_dict = {name: tf.convert_to_tensor(value) for name, value in sample.items()}\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.42210525]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = inference_model.predict(input_dict)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06226229],\n",
       "       [0.98524046],\n",
       "       [0.42210528],\n",
       "       [0.9874074 ],\n",
       "       [0.0602196 ],\n",
       "       [0.03987905],\n",
       "       [0.2555308 ],\n",
       "       [0.04276018],\n",
       "       [0.8191519 ],\n",
       "       [0.9810582 ],\n",
       "       [0.54381096],\n",
       "       [0.9705486 ],\n",
       "       [0.06773431],\n",
       "       [0.03616178],\n",
       "       [0.36961085],\n",
       "       [0.8797046 ],\n",
       "       [0.02858267],\n",
       "       [0.0935005 ],\n",
       "       [0.19146827],\n",
       "       [0.6111609 ],\n",
       "       [0.06280035],\n",
       "       [0.05715452],\n",
       "       [0.83902884],\n",
       "       [0.47905535],\n",
       "       [0.12111206],\n",
       "       [0.06434729],\n",
       "       [0.08680065],\n",
       "       [0.07200352],\n",
       "       [0.83865976],\n",
       "       [0.04605198],\n",
       "       [0.19396788],\n",
       "       [0.99547225],\n",
       "       [0.83834136],\n",
       "       [0.05598091],\n",
       "       [0.09861276],\n",
       "       [0.28420934],\n",
       "       [0.08680216],\n",
       "       [0.06773431],\n",
       "       [0.19417575],\n",
       "       [0.4704881 ],\n",
       "       [0.12461109],\n",
       "       [0.8568641 ],\n",
       "       [0.08704498],\n",
       "       [0.9513536 ],\n",
       "       [0.41686213],\n",
       "       [0.0461596 ],\n",
       "       [0.07946019],\n",
       "       [0.83834136],\n",
       "       [0.19827637],\n",
       "       [0.3949044 ],\n",
       "       [0.01839225],\n",
       "       [0.06747911],\n",
       "       [0.986849  ],\n",
       "       [0.95283043],\n",
       "       [0.19679676],\n",
       "       [0.25030407],\n",
       "       [0.9170681 ],\n",
       "       [0.20809646],\n",
       "       [0.9212719 ],\n",
       "       [0.00747689],\n",
       "       [0.1402946 ],\n",
       "       [0.9959955 ],\n",
       "       [0.35224858],\n",
       "       [0.07966739],\n",
       "       [0.12535122],\n",
       "       [0.67305267],\n",
       "       [0.96213585],\n",
       "       [0.06784517],\n",
       "       [0.09991685],\n",
       "       [0.10289884],\n",
       "       [0.15130086],\n",
       "       [0.03506642],\n",
       "       [0.11313321],\n",
       "       [0.22417943],\n",
       "       [0.22775619],\n",
       "       [0.14064504],\n",
       "       [0.04605198],\n",
       "       [0.0461596 ],\n",
       "       [0.9581012 ],\n",
       "       [0.3534098 ],\n",
       "       [0.06868816],\n",
       "       [0.17800981],\n",
       "       [0.8384338 ],\n",
       "       [0.3725125 ],\n",
       "       [0.9709616 ],\n",
       "       [0.8610686 ],\n",
       "       [0.28033492],\n",
       "       [0.0461596 ],\n",
       "       [0.96364224],\n",
       "       [0.14089689],\n",
       "       [0.17447144],\n",
       "       [0.06753437],\n",
       "       [0.2988197 ],\n",
       "       [0.11989029],\n",
       "       [0.05961954],\n",
       "       [0.0461596 ],\n",
       "       [0.20646822],\n",
       "       [0.7646003 ],\n",
       "       [0.93758124],\n",
       "       [0.06475088],\n",
       "       [0.3311239 ],\n",
       "       [0.04605198],\n",
       "       [0.2714603 ],\n",
       "       [0.06067657],\n",
       "       [0.04109845],\n",
       "       [0.17409845],\n",
       "       [0.5044128 ],\n",
       "       [0.04596781],\n",
       "       [0.06010351],\n",
       "       [0.9010119 ],\n",
       "       [0.25569272],\n",
       "       [0.49302778],\n",
       "       [0.06773431],\n",
       "       [0.3125505 ],\n",
       "       [0.64348453],\n",
       "       [0.0676066 ],\n",
       "       [0.05761185],\n",
       "       [0.1347847 ],\n",
       "       [0.05761518],\n",
       "       [0.08463882],\n",
       "       [0.12364434],\n",
       "       [0.0461596 ],\n",
       "       [0.11390399],\n",
       "       [0.9640393 ],\n",
       "       [0.17471968],\n",
       "       [0.1659725 ],\n",
       "       [0.03975681],\n",
       "       [0.14032555],\n",
       "       [0.8347539 ],\n",
       "       [0.05941455],\n",
       "       [0.09890594],\n",
       "       [0.06671876],\n",
       "       [0.13368855],\n",
       "       [0.95283043],\n",
       "       [0.09551204],\n",
       "       [0.10859294],\n",
       "       [0.95891285],\n",
       "       [0.28562123],\n",
       "       [0.04698175],\n",
       "       [0.5821829 ],\n",
       "       [0.64810646],\n",
       "       [0.5049163 ],\n",
       "       [0.58708787],\n",
       "       [0.05751065],\n",
       "       [0.06793886],\n",
       "       [0.20765285],\n",
       "       [0.14073677],\n",
       "       [0.1684034 ],\n",
       "       [0.12197479],\n",
       "       [0.05715452],\n",
       "       [0.05692976],\n",
       "       [0.9866    ],\n",
       "       [0.0602196 ],\n",
       "       [0.08126274],\n",
       "       [0.04564698],\n",
       "       [0.19733055],\n",
       "       [0.8383001 ],\n",
       "       [0.17447144],\n",
       "       [0.04658949],\n",
       "       [0.00124422],\n",
       "       [0.09724903],\n",
       "       [0.87915266],\n",
       "       [0.1407237 ],\n",
       "       [0.04658949],\n",
       "       [0.01839225],\n",
       "       [0.8053551 ],\n",
       "       [0.9715816 ],\n",
       "       [0.08709667],\n",
       "       [0.24971439],\n",
       "       [0.22775619],\n",
       "       [0.25375462],\n",
       "       [0.02858267],\n",
       "       [0.53656363],\n",
       "       [0.0676066 ],\n",
       "       [0.19925992],\n",
       "       [0.1166882 ],\n",
       "       [0.04140177],\n",
       "       [0.9247515 ],\n",
       "       [0.15484886],\n",
       "       [0.0542559 ],\n",
       "       [0.0047003 ],\n",
       "       [0.2501386 ],\n",
       "       [0.017764  ],\n",
       "       [0.8807998 ],\n",
       "       [0.22570741],\n",
       "       [0.23165666],\n",
       "       [0.89520925],\n",
       "       [0.2538313 ],\n",
       "       [0.07990593],\n",
       "       [0.06010351],\n",
       "       [0.9640393 ],\n",
       "       [0.06854834],\n",
       "       [0.2948041 ],\n",
       "       [0.935436  ],\n",
       "       [0.9230669 ],\n",
       "       [0.993996  ],\n",
       "       [0.03975681],\n",
       "       [0.09310997],\n",
       "       [0.83834136],\n",
       "       [0.81618434],\n",
       "       [0.17800981],\n",
       "       [0.00124422],\n",
       "       [0.05905895],\n",
       "       [0.09828454],\n",
       "       [0.06773431],\n",
       "       [0.6096976 ],\n",
       "       [0.09924887],\n",
       "       [0.1963347 ],\n",
       "       [0.83834136],\n",
       "       [0.19980708],\n",
       "       [0.14026795],\n",
       "       [0.89029366],\n",
       "       [0.06692073],\n",
       "       [0.15484886],\n",
       "       [0.07420748],\n",
       "       [0.9891734 ],\n",
       "       [0.42210528],\n",
       "       [0.0655268 ],\n",
       "       [0.98750526],\n",
       "       [0.15130086],\n",
       "       [0.0461596 ],\n",
       "       [0.09551204],\n",
       "       [0.0602196 ],\n",
       "       [0.04605198],\n",
       "       [0.36831865],\n",
       "       [0.06899592],\n",
       "       [0.06753533],\n",
       "       [0.06692073],\n",
       "       [0.06854834],\n",
       "       [0.11758777],\n",
       "       [0.99044997],\n",
       "       [0.17380665],\n",
       "       [0.057392  ],\n",
       "       [0.08458193],\n",
       "       [0.09402158],\n",
       "       [0.36803618],\n",
       "       [0.06475088],\n",
       "       [0.93844855],\n",
       "       [0.06753533],\n",
       "       [0.05681181],\n",
       "       [0.49302778],\n",
       "       [0.89520925],\n",
       "       [0.15130086],\n",
       "       [0.06679444],\n",
       "       [0.20809709],\n",
       "       [0.14394718],\n",
       "       [0.42177045],\n",
       "       [0.9548673 ],\n",
       "       [0.38018644],\n",
       "       [0.06475088],\n",
       "       [0.04560379],\n",
       "       [0.2594026 ],\n",
       "       [0.2538313 ],\n",
       "       [0.09961331],\n",
       "       [0.2498641 ],\n",
       "       [0.830217  ],\n",
       "       [0.98189205],\n",
       "       [0.99378663],\n",
       "       [0.99996036],\n",
       "       [0.94124204],\n",
       "       [0.03975681],\n",
       "       [0.017764  ],\n",
       "       [0.2585109 ],\n",
       "       [0.18719801],\n",
       "       [0.83834136],\n",
       "       [0.05598091],\n",
       "       [0.01839225],\n",
       "       [0.13740422],\n",
       "       [0.99358547],\n",
       "       [0.99426955],\n",
       "       [0.25701666],\n",
       "       [0.13546522],\n",
       "       [0.93302435],\n",
       "       [0.2423856 ],\n",
       "       [0.83834136],\n",
       "       [0.9899165 ],\n",
       "       [0.1640073 ],\n",
       "       [0.07665209],\n",
       "       [0.02858267],\n",
       "       [0.52359223],\n",
       "       [0.05761185],\n",
       "       [0.17399792],\n",
       "       [0.04718346],\n",
       "       [0.06773431],\n",
       "       [0.24986939],\n",
       "       [0.09962045],\n",
       "       [0.17800981],\n",
       "       [0.06757682],\n",
       "       [0.05715452],\n",
       "       [0.4158461 ],\n",
       "       [0.98566025],\n",
       "       [0.9897382 ],\n",
       "       [0.08054705],\n",
       "       [0.424376  ],\n",
       "       [0.14079978],\n",
       "       [0.12535122],\n",
       "       [0.1800962 ],\n",
       "       [0.73024356],\n",
       "       [0.25664636],\n",
       "       [0.9978074 ],\n",
       "       [0.83834136],\n",
       "       [0.32254964],\n",
       "       [0.06013935],\n",
       "       [0.98356545],\n",
       "       [0.0461596 ],\n",
       "       [0.70891035],\n",
       "       [0.98888886],\n",
       "       [0.9930657 ],\n",
       "       [0.11102185],\n",
       "       [0.9846201 ],\n",
       "       [0.9900286 ],\n",
       "       [0.98932236],\n",
       "       [0.87961924],\n",
       "       [0.17409845],\n",
       "       [0.12754421],\n",
       "       [0.42194727],\n",
       "       [0.8608584 ],\n",
       "       [0.05763041],\n",
       "       [0.9282687 ],\n",
       "       [0.9919764 ],\n",
       "       [0.06692073],\n",
       "       [0.14079978],\n",
       "       [0.93932724],\n",
       "       [0.9683775 ],\n",
       "       [0.00124422],\n",
       "       [0.9940604 ],\n",
       "       [0.05886808],\n",
       "       [0.8720975 ],\n",
       "       [0.2861157 ],\n",
       "       [0.9794188 ],\n",
       "       [0.8504887 ],\n",
       "       [0.25380984],\n",
       "       [0.1439339 ],\n",
       "       [0.07035928],\n",
       "       [0.98948795],\n",
       "       [0.04605198],\n",
       "       [0.14216274],\n",
       "       [0.99406767],\n",
       "       [0.0602196 ],\n",
       "       [0.2537326 ],\n",
       "       [0.935436  ],\n",
       "       [0.96364224],\n",
       "       [0.15484886],\n",
       "       [0.09551204],\n",
       "       [0.05715452],\n",
       "       [0.81618434],\n",
       "       [0.8720975 ],\n",
       "       [0.45829543],\n",
       "       [0.7920437 ],\n",
       "       [0.06068285],\n",
       "       [0.14163886],\n",
       "       [0.25111696],\n",
       "       [0.6491191 ],\n",
       "       [0.14112021],\n",
       "       [0.08680065],\n",
       "       [0.17800981],\n",
       "       [0.98518825],\n",
       "       [0.8720975 ],\n",
       "       [0.83865976],\n",
       "       [0.83865976],\n",
       "       [0.05561107],\n",
       "       [0.1131337 ],\n",
       "       [0.61621237],\n",
       "       [0.05947039],\n",
       "       [0.07946019],\n",
       "       [0.17254312],\n",
       "       [0.986434  ],\n",
       "       [0.61118364],\n",
       "       [0.83834136],\n",
       "       [0.98841304],\n",
       "       [0.8246706 ],\n",
       "       [0.06150243],\n",
       "       [0.06773431],\n",
       "       [0.24094951],\n",
       "       [0.12111206],\n",
       "       [0.9891345 ],\n",
       "       [0.50239813],\n",
       "       [0.06809592],\n",
       "       [0.13638236],\n",
       "       [0.06745363],\n",
       "       [0.99600184],\n",
       "       [0.64603406],\n",
       "       [0.17416905],\n",
       "       [0.9872686 ],\n",
       "       [0.04605198],\n",
       "       [0.11313321],\n",
       "       [0.00747689],\n",
       "       [0.8720975 ],\n",
       "       [0.03975321],\n",
       "       [0.94318736],\n",
       "       [0.13402113],\n",
       "       [0.06747481],\n",
       "       [0.04022051],\n",
       "       [0.9920936 ],\n",
       "       [0.82675564],\n",
       "       [0.06747481],\n",
       "       [0.33092654],\n",
       "       [0.06280035],\n",
       "       [0.09402158],\n",
       "       [0.9637786 ],\n",
       "       [0.06012549],\n",
       "       [0.14089689],\n",
       "       [0.3125505 ],\n",
       "       [0.09924887],\n",
       "       [0.5095116 ],\n",
       "       [0.06096161],\n",
       "       [0.05999392],\n",
       "       [0.92453945],\n",
       "       [0.06745363],\n",
       "       [0.11758777],\n",
       "       [0.04605198],\n",
       "       [0.0396034 ],\n",
       "       [0.99198514],\n",
       "       [0.07665209],\n",
       "       [0.06012549],\n",
       "       [0.37062582],\n",
       "       [0.9459999 ],\n",
       "       [0.96656173],\n",
       "       [0.15484886],\n",
       "       [0.22639091],\n",
       "       [0.08704498],\n",
       "       [0.05807406],\n",
       "       [0.17404819],\n",
       "       [0.26933444],\n",
       "       [0.12415101],\n",
       "       [0.04560379],\n",
       "       [0.95283043],\n",
       "       [0.93398166],\n",
       "       [0.03975681],\n",
       "       [0.17447144],\n",
       "       [0.53912616],\n",
       "       [0.45829543],\n",
       "       [0.8901389 ],\n",
       "       [0.04551754],\n",
       "       [0.28953192],\n",
       "       [0.73984313],\n",
       "       [0.33701578],\n",
       "       [0.8836237 ],\n",
       "       [0.03780229],\n",
       "       [0.15130086],\n",
       "       [0.9386749 ],\n",
       "       [0.06912817],\n",
       "       [0.13740422],\n",
       "       [0.9640393 ],\n",
       "       [0.04620329],\n",
       "       [0.9198796 ],\n",
       "       [0.9782036 ],\n",
       "       [0.2538313 ],\n",
       "       [0.8896903 ],\n",
       "       [0.25378776],\n",
       "       [0.14408521],\n",
       "       [0.06037207],\n",
       "       [0.14406337],\n",
       "       [0.40916172],\n",
       "       [0.0461596 ],\n",
       "       [0.20800014],\n",
       "       [0.2538313 ],\n",
       "       [0.97121036],\n",
       "       [0.86540353],\n",
       "       [0.03975681],\n",
       "       [0.2538313 ],\n",
       "       [0.0602196 ],\n",
       "       [0.25347102],\n",
       "       [0.05715452],\n",
       "       [0.0461596 ],\n",
       "       [0.05947039],\n",
       "       [0.07665209],\n",
       "       [0.2538313 ],\n",
       "       [0.03975248],\n",
       "       [0.8896903 ],\n",
       "       [0.04560379],\n",
       "       [0.06068285],\n",
       "       [0.9089248 ],\n",
       "       [0.8589129 ],\n",
       "       [0.51551867],\n",
       "       [0.2343989 ],\n",
       "       [0.06096161],\n",
       "       [0.08720516],\n",
       "       [0.0671951 ],\n",
       "       [0.607389  ],\n",
       "       [0.00747689],\n",
       "       [0.07665209],\n",
       "       [0.0602196 ],\n",
       "       [0.16859917],\n",
       "       [0.65726006],\n",
       "       [0.11758777],\n",
       "       [0.9911326 ],\n",
       "       [0.19747655],\n",
       "       [0.17447144],\n",
       "       [0.7920437 ],\n",
       "       [0.06037207],\n",
       "       [0.06692073],\n",
       "       [0.25378776],\n",
       "       [0.20943835],\n",
       "       [0.06773431],\n",
       "       [0.08946828],\n",
       "       [0.9872331 ],\n",
       "       [0.05202322],\n",
       "       [0.96260166],\n",
       "       [0.14073677],\n",
       "       [0.04658949],\n",
       "       [0.4158461 ],\n",
       "       [0.8380431 ],\n",
       "       [0.16859917],\n",
       "       [0.9774817 ],\n",
       "       [0.21936184],\n",
       "       [0.92883915],\n",
       "       [0.2510079 ],\n",
       "       [0.19512902],\n",
       "       [0.1698068 ],\n",
       "       [0.16926402],\n",
       "       [0.0461596 ],\n",
       "       [0.25383422],\n",
       "       [0.98062897],\n",
       "       [0.14054805],\n",
       "       [0.25374892],\n",
       "       [0.86540353],\n",
       "       [0.04581727],\n",
       "       [0.8901389 ],\n",
       "       [0.17409845],\n",
       "       [0.9942784 ],\n",
       "       [0.06757682],\n",
       "       [0.08680065],\n",
       "       [0.97696143],\n",
       "       [0.08680216],\n",
       "       [0.05761185],\n",
       "       [0.86540353],\n",
       "       [0.10893155],\n",
       "       [0.06012549],\n",
       "       [0.10859369],\n",
       "       [0.97180927],\n",
       "       [0.08680216],\n",
       "       [0.6491191 ],\n",
       "       [0.6159649 ],\n",
       "       [0.3347696 ],\n",
       "       [0.93844855],\n",
       "       [0.2538313 ],\n",
       "       [0.99175787],\n",
       "       [0.05145799],\n",
       "       [0.98286384],\n",
       "       [0.960636  ],\n",
       "       [0.08463882],\n",
       "       [0.08463882],\n",
       "       [0.14472537],\n",
       "       [0.3766736 ],\n",
       "       [0.25383747],\n",
       "       [0.9462282 ],\n",
       "       [0.2539291 ],\n",
       "       [0.089031  ],\n",
       "       [0.9476015 ],\n",
       "       [0.94469035],\n",
       "       [0.10453386],\n",
       "       [0.03977047],\n",
       "       [0.14028943],\n",
       "       [0.5050423 ],\n",
       "       [0.2538313 ],\n",
       "       [0.96673363],\n",
       "       [0.13939321],\n",
       "       [0.9756751 ],\n",
       "       [0.14065152],\n",
       "       [0.03975681],\n",
       "       [0.06010351],\n",
       "       [0.15557672],\n",
       "       [0.0461596 ],\n",
       "       [0.37062582],\n",
       "       [0.11454508],\n",
       "       [0.06757682],\n",
       "       [0.09156284],\n",
       "       [0.08680216],\n",
       "       [0.17399792],\n",
       "       [0.05598091],\n",
       "       [0.98319477],\n",
       "       [0.2538331 ],\n",
       "       [0.83834136],\n",
       "       [0.0461596 ],\n",
       "       [0.07367381],\n",
       "       [0.8720975 ],\n",
       "       [0.9877045 ],\n",
       "       [0.4930709 ],\n",
       "       [0.17416905],\n",
       "       [0.8835632 ],\n",
       "       [0.9891901 ],\n",
       "       [0.06280035],\n",
       "       [0.21110089],\n",
       "       [0.08734329],\n",
       "       [0.97908604],\n",
       "       [0.05811002],\n",
       "       [0.4385697 ],\n",
       "       [0.06773431],\n",
       "       [0.0461596 ],\n",
       "       [0.05952628],\n",
       "       [0.9872331 ],\n",
       "       [0.05961954],\n",
       "       [0.25815523],\n",
       "       [0.06475088],\n",
       "       [0.09180216],\n",
       "       [0.97889555],\n",
       "       [0.0542559 ],\n",
       "       [0.08680065],\n",
       "       [0.36112618],\n",
       "       [0.7919454 ],\n",
       "       [0.04605198],\n",
       "       [0.23922138],\n",
       "       [0.0602196 ],\n",
       "       [0.19191475],\n",
       "       [0.05666218],\n",
       "       [0.17409845],\n",
       "       [0.7831022 ],\n",
       "       [0.94431096],\n",
       "       [0.99538684],\n",
       "       [0.06439568],\n",
       "       [0.04546585],\n",
       "       [0.89520925],\n",
       "       [0.03975681],\n",
       "       [0.0602196 ],\n",
       "       [0.94319504],\n",
       "       [0.08458671],\n",
       "       [0.58716595],\n",
       "       [0.95469797],\n",
       "       [0.09402158],\n",
       "       [0.22417943],\n",
       "       [0.28491834],\n",
       "       [0.30378765],\n",
       "       [0.06753437],\n",
       "       [0.0751856 ],\n",
       "       [0.25376773],\n",
       "       [0.04215306],\n",
       "       [0.99006206],\n",
       "       [0.14079978],\n",
       "       [0.03975393],\n",
       "       [0.2537932 ],\n",
       "       [0.05947352],\n",
       "       [0.14337398],\n",
       "       [0.15361188],\n",
       "       [0.14780575],\n",
       "       [0.9640393 ],\n",
       "       [0.17416905],\n",
       "       [0.22061239],\n",
       "       [0.05080682],\n",
       "       [0.05599888],\n",
       "       [0.06753437],\n",
       "       [0.98841304],\n",
       "       [0.14780575],\n",
       "       [0.11405413],\n",
       "       [0.8896903 ],\n",
       "       [0.39686075],\n",
       "       [0.06757682],\n",
       "       [0.2076649 ],\n",
       "       [0.04581146],\n",
       "       [0.42126828],\n",
       "       [0.04605198],\n",
       "       [0.9571087 ],\n",
       "       [0.06812738],\n",
       "       [0.8385366 ],\n",
       "       [0.4086549 ],\n",
       "       [0.10526569],\n",
       "       [0.04605198],\n",
       "       [0.22656426],\n",
       "       [0.09551204],\n",
       "       [0.15568815],\n",
       "       [0.65944463],\n",
       "       [0.09828454],\n",
       "       [0.25384203],\n",
       "       [0.0598033 ],\n",
       "       [0.06294975],\n",
       "       [0.09681793],\n",
       "       [0.09551204],\n",
       "       [0.04596781],\n",
       "       [0.0602196 ],\n",
       "       [0.9712321 ],\n",
       "       [0.9525913 ],\n",
       "       [0.16251747],\n",
       "       [0.05598091],\n",
       "       [0.15484886],\n",
       "       [0.07665209],\n",
       "       [0.06745363],\n",
       "       [0.14089689],\n",
       "       [0.5155413 ],\n",
       "       [0.03390043],\n",
       "       [0.92516696],\n",
       "       [0.83929485],\n",
       "       [0.5968107 ],\n",
       "       [0.06888585],\n",
       "       [0.00747689],\n",
       "       [0.13237277],\n",
       "       [0.17904185],\n",
       "       [0.01839225],\n",
       "       [0.06972259],\n",
       "       [0.06747481],\n",
       "       [0.98783803],\n",
       "       [0.151874  ],\n",
       "       [0.76191247],\n",
       "       [0.11405413],\n",
       "       [0.18009059],\n",
       "       [0.2538313 ],\n",
       "       [0.057392  ],\n",
       "       [0.0602196 ],\n",
       "       [0.8383001 ],\n",
       "       [0.2542382 ],\n",
       "       [0.05991887],\n",
       "       [0.9964122 ],\n",
       "       [0.25383422],\n",
       "       [0.7313816 ],\n",
       "       [0.10061001],\n",
       "       [0.13743918],\n",
       "       [0.06280035],\n",
       "       [0.87333053],\n",
       "       [0.25383422],\n",
       "       [0.9962247 ],\n",
       "       [0.67305267],\n",
       "       [0.98457336],\n",
       "       [0.2510079 ],\n",
       "       [0.28420934],\n",
       "       [0.17796877],\n",
       "       [0.05715452],\n",
       "       [0.0673264 ],\n",
       "       [0.99600184],\n",
       "       [0.80823064],\n",
       "       [0.04194856],\n",
       "       [0.06001269],\n",
       "       [0.9790021 ],\n",
       "       [0.04775736],\n",
       "       [0.05715452],\n",
       "       [0.05715452],\n",
       "       [0.8159975 ],\n",
       "       [0.06836342],\n",
       "       [0.730278  ],\n",
       "       [0.8383105 ],\n",
       "       [0.10361991],\n",
       "       [0.58461106],\n",
       "       [0.9960315 ],\n",
       "       [0.09217218],\n",
       "       [0.07665209],\n",
       "       [0.09551204],\n",
       "       [0.09551204],\n",
       "       [0.18825218],\n",
       "       [0.11113   ],\n",
       "       [0.97800916],\n",
       "       [0.04605198],\n",
       "       [0.04605198],\n",
       "       [0.25627646],\n",
       "       [0.3441683 ],\n",
       "       [0.98932236],\n",
       "       [0.14059752],\n",
       "       [0.17416905],\n",
       "       [0.29432496],\n",
       "       [0.7955698 ],\n",
       "       [0.9640393 ],\n",
       "       [0.2538469 ],\n",
       "       [0.16926402],\n",
       "       [0.97070664],\n",
       "       [0.6498854 ],\n",
       "       [0.06132169],\n",
       "       [0.14079978],\n",
       "       [0.93584967],\n",
       "       [0.9189398 ],\n",
       "       [0.1738569 ],\n",
       "       [0.06793886],\n",
       "       [0.0602196 ],\n",
       "       [0.9904922 ],\n",
       "       [0.05145799],\n",
       "       [0.05952628],\n",
       "       [0.1402946 ],\n",
       "       [0.9435794 ],\n",
       "       [0.04596781],\n",
       "       [0.9899165 ],\n",
       "       [0.11361231],\n",
       "       [0.22368003],\n",
       "       [0.0865883 ],\n",
       "       [0.17522931],\n",
       "       [0.14181298],\n",
       "       [0.06007222],\n",
       "       [0.86540353],\n",
       "       [0.08680065],\n",
       "       [0.7951269 ],\n",
       "       [0.06742815],\n",
       "       [0.03975681],\n",
       "       [0.393855  ],\n",
       "       [0.03975465],\n",
       "       [0.9966976 ],\n",
       "       [0.61118364],\n",
       "       [0.97263455],\n",
       "       [0.5204942 ],\n",
       "       [0.7696982 ],\n",
       "       [0.14026795],\n",
       "       [0.14039357],\n",
       "       [0.5036362 ],\n",
       "       [0.02858267],\n",
       "       [0.781712  ],\n",
       "       [0.19348067],\n",
       "       [0.03975681],\n",
       "       [0.11802173],\n",
       "       [0.0047003 ],\n",
       "       [0.12192321],\n",
       "       [0.14079978],\n",
       "       [0.05715452],\n",
       "       [0.9701443 ],\n",
       "       [0.33486885],\n",
       "       [0.20809646],\n",
       "       [0.29554498],\n",
       "       [0.05715452],\n",
       "       [0.94845074],\n",
       "       [0.78622687],\n",
       "       [0.63319564],\n",
       "       [0.14022091],\n",
       "       [0.17380665],\n",
       "       [0.18719801],\n",
       "       [0.5050423 ],\n",
       "       [0.05715452],\n",
       "       [0.9874074 ],\n",
       "       [0.14079453],\n",
       "       [0.07259628],\n",
       "       [0.05598091],\n",
       "       [0.08463882],\n",
       "       [0.17447144],\n",
       "       [0.15361188],\n",
       "       [0.42210528],\n",
       "       [0.1547253 ],\n",
       "       [0.05902503],\n",
       "       [0.07966739],\n",
       "       [0.9792326 ],\n",
       "       [0.14128326],\n",
       "       [0.18719801],\n",
       "       [0.71961236],\n",
       "       [0.01839225],\n",
       "       [0.03961917],\n",
       "       [0.11405413],\n",
       "       [0.9354738 ],\n",
       "       [0.03975681],\n",
       "       [0.9959955 ],\n",
       "       [0.49302778],\n",
       "       [0.92453945],\n",
       "       [0.08680216],\n",
       "       [0.14077356],\n",
       "       [0.06799044],\n",
       "       [0.9820415 ],\n",
       "       [0.06836342],\n",
       "       [0.0461596 ],\n",
       "       [0.22775619],\n",
       "       [0.12305316],\n",
       "       [0.0676066 ],\n",
       "       [0.0899969 ],\n",
       "       [0.97825503],\n",
       "       [0.09755953],\n",
       "       [0.04658949],\n",
       "       [0.05984391],\n",
       "       [0.00124422],\n",
       "       [0.09890594],\n",
       "       [0.20571648],\n",
       "       [0.9904919 ],\n",
       "       [0.01775489],\n",
       "       [0.06001269],\n",
       "       [0.8442625 ],\n",
       "       [0.9688769 ],\n",
       "       [0.8901389 ],\n",
       "       [0.69636023],\n",
       "       [0.9911335 ],\n",
       "       [0.2538313 ],\n",
       "       [0.8246001 ],\n",
       "       [0.08680216],\n",
       "       [0.04494499],\n",
       "       [0.07581635],\n",
       "       [0.9701443 ],\n",
       "       [0.0047003 ],\n",
       "       [0.09551204],\n",
       "       [0.8720975 ],\n",
       "       [0.9097231 ],\n",
       "       [0.34998083],\n",
       "       [0.04718346],\n",
       "       [0.7772251 ],\n",
       "       [0.14079978],\n",
       "       [0.9694622 ],\n",
       "       [0.20195459],\n",
       "       [0.06093955],\n",
       "       [0.93341434],\n",
       "       [0.6111609 ],\n",
       "       [0.06943402],\n",
       "       [0.06757682],\n",
       "       [0.04605198],\n",
       "       [0.986163  ],\n",
       "       [0.9453853 ],\n",
       "       [0.06010351],\n",
       "       [0.519191  ],\n",
       "       [0.15130086],\n",
       "       [0.14026795],\n",
       "       [0.05485353],\n",
       "       [0.09551204],\n",
       "       [0.9795868 ],\n",
       "       [0.1592902 ],\n",
       "       [0.76310796],\n",
       "       [0.16926402]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = inference_model.predict(x=titanic_dataset)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "       508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n",
       "       521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533,\n",
       "       534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546,\n",
       "       547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
       "       560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
       "       573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585,\n",
       "       586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598,\n",
       "       599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611,\n",
       "       612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624,\n",
       "       625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637,\n",
       "       638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650,\n",
       "       651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663,\n",
       "       664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676,\n",
       "       677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689,\n",
       "       690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702,\n",
       "       703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715,\n",
       "       716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728,\n",
       "       729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741,\n",
       "       742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754,\n",
       "       755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767,\n",
       "       768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780,\n",
       "       781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793,\n",
       "       794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806,\n",
       "       807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819,\n",
       "       820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832,\n",
       "       833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845,\n",
       "       846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858,\n",
       "       859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871,\n",
       "       872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884,\n",
       "       885, 886, 887, 888, 889, 890, 891])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passanger_id = np.arange(1, len(predictions) + 1)\n",
    "passanger_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06226229, 0.98524046, 0.42210528, 0.9874074 , 0.0602196 ,\n",
       "       0.03987905, 0.2555308 , 0.04276018, 0.8191519 , 0.9810582 ,\n",
       "       0.54381096, 0.9705486 , 0.06773431, 0.03616178, 0.36961085,\n",
       "       0.8797046 , 0.02858267, 0.0935005 , 0.19146827, 0.6111609 ,\n",
       "       0.06280035, 0.05715452, 0.83902884, 0.47905535, 0.12111206,\n",
       "       0.06434729, 0.08680065, 0.07200352, 0.83865976, 0.04605198,\n",
       "       0.19396788, 0.99547225, 0.83834136, 0.05598091, 0.09861276,\n",
       "       0.28420934, 0.08680216, 0.06773431, 0.19417575, 0.4704881 ,\n",
       "       0.12461109, 0.8568641 , 0.08704498, 0.9513536 , 0.41686213,\n",
       "       0.0461596 , 0.07946019, 0.83834136, 0.19827637, 0.3949044 ,\n",
       "       0.01839225, 0.06747911, 0.986849  , 0.95283043, 0.19679676,\n",
       "       0.25030407, 0.9170681 , 0.20809646, 0.9212719 , 0.00747689,\n",
       "       0.1402946 , 0.9959955 , 0.35224858, 0.07966739, 0.12535122,\n",
       "       0.67305267, 0.96213585, 0.06784517, 0.09991685, 0.10289884,\n",
       "       0.15130086, 0.03506642, 0.11313321, 0.22417943, 0.22775619,\n",
       "       0.14064504, 0.04605198, 0.0461596 , 0.9581012 , 0.3534098 ,\n",
       "       0.06868816, 0.17800981, 0.8384338 , 0.3725125 , 0.9709616 ,\n",
       "       0.8610686 , 0.28033492, 0.0461596 , 0.96364224, 0.14089689,\n",
       "       0.17447144, 0.06753437, 0.2988197 , 0.11989029, 0.05961954,\n",
       "       0.0461596 , 0.20646822, 0.7646003 , 0.93758124, 0.06475088,\n",
       "       0.3311239 , 0.04605198, 0.2714603 , 0.06067657, 0.04109845,\n",
       "       0.17409845, 0.5044128 , 0.04596781, 0.06010351, 0.9010119 ,\n",
       "       0.25569272, 0.49302778, 0.06773431, 0.3125505 , 0.64348453,\n",
       "       0.0676066 , 0.05761185, 0.1347847 , 0.05761518, 0.08463882,\n",
       "       0.12364434, 0.0461596 , 0.11390399, 0.9640393 , 0.17471968,\n",
       "       0.1659725 , 0.03975681, 0.14032555, 0.8347539 , 0.05941455,\n",
       "       0.09890594, 0.06671876, 0.13368855, 0.95283043, 0.09551204,\n",
       "       0.10859294, 0.95891285, 0.28562123, 0.04698175, 0.5821829 ,\n",
       "       0.64810646, 0.5049163 , 0.58708787, 0.05751065, 0.06793886,\n",
       "       0.20765285, 0.14073677, 0.1684034 , 0.12197479, 0.05715452,\n",
       "       0.05692976, 0.9866    , 0.0602196 , 0.08126274, 0.04564698,\n",
       "       0.19733055, 0.8383001 , 0.17447144, 0.04658949, 0.00124422,\n",
       "       0.09724903, 0.87915266, 0.1407237 , 0.04658949, 0.01839225,\n",
       "       0.8053551 , 0.9715816 , 0.08709667, 0.24971439, 0.22775619,\n",
       "       0.25375462, 0.02858267, 0.53656363, 0.0676066 , 0.19925992,\n",
       "       0.1166882 , 0.04140177, 0.9247515 , 0.15484886, 0.0542559 ,\n",
       "       0.0047003 , 0.2501386 , 0.017764  , 0.8807998 , 0.22570741,\n",
       "       0.23165666, 0.89520925, 0.2538313 , 0.07990593, 0.06010351,\n",
       "       0.9640393 , 0.06854834, 0.2948041 , 0.935436  , 0.9230669 ,\n",
       "       0.993996  , 0.03975681, 0.09310997, 0.83834136, 0.81618434,\n",
       "       0.17800981, 0.00124422, 0.05905895, 0.09828454, 0.06773431,\n",
       "       0.6096976 , 0.09924887, 0.1963347 , 0.83834136, 0.19980708,\n",
       "       0.14026795, 0.89029366, 0.06692073, 0.15484886, 0.07420748,\n",
       "       0.9891734 , 0.42210528, 0.0655268 , 0.98750526, 0.15130086,\n",
       "       0.0461596 , 0.09551204, 0.0602196 , 0.04605198, 0.36831865,\n",
       "       0.06899592, 0.06753533, 0.06692073, 0.06854834, 0.11758777,\n",
       "       0.99044997, 0.17380665, 0.057392  , 0.08458193, 0.09402158,\n",
       "       0.36803618, 0.06475088, 0.93844855, 0.06753533, 0.05681181,\n",
       "       0.49302778, 0.89520925, 0.15130086, 0.06679444, 0.20809709,\n",
       "       0.14394718, 0.42177045, 0.9548673 , 0.38018644, 0.06475088,\n",
       "       0.04560379, 0.2594026 , 0.2538313 , 0.09961331, 0.2498641 ,\n",
       "       0.830217  , 0.98189205, 0.99378663, 0.99996036, 0.94124204,\n",
       "       0.03975681, 0.017764  , 0.2585109 , 0.18719801, 0.83834136,\n",
       "       0.05598091, 0.01839225, 0.13740422, 0.99358547, 0.99426955,\n",
       "       0.25701666, 0.13546522, 0.93302435, 0.2423856 , 0.83834136,\n",
       "       0.9899165 , 0.1640073 , 0.07665209, 0.02858267, 0.52359223,\n",
       "       0.05761185, 0.17399792, 0.04718346, 0.06773431, 0.24986939,\n",
       "       0.09962045, 0.17800981, 0.06757682, 0.05715452, 0.4158461 ,\n",
       "       0.98566025, 0.9897382 , 0.08054705, 0.424376  , 0.14079978,\n",
       "       0.12535122, 0.1800962 , 0.73024356, 0.25664636, 0.9978074 ,\n",
       "       0.83834136, 0.32254964, 0.06013935, 0.98356545, 0.0461596 ,\n",
       "       0.70891035, 0.98888886, 0.9930657 , 0.11102185, 0.9846201 ,\n",
       "       0.9900286 , 0.98932236, 0.87961924, 0.17409845, 0.12754421,\n",
       "       0.42194727, 0.8608584 , 0.05763041, 0.9282687 , 0.9919764 ,\n",
       "       0.06692073, 0.14079978, 0.93932724, 0.9683775 , 0.00124422,\n",
       "       0.9940604 , 0.05886808, 0.8720975 , 0.2861157 , 0.9794188 ,\n",
       "       0.8504887 , 0.25380984, 0.1439339 , 0.07035928, 0.98948795,\n",
       "       0.04605198, 0.14216274, 0.99406767, 0.0602196 , 0.2537326 ,\n",
       "       0.935436  , 0.96364224, 0.15484886, 0.09551204, 0.05715452,\n",
       "       0.81618434, 0.8720975 , 0.45829543, 0.7920437 , 0.06068285,\n",
       "       0.14163886, 0.25111696, 0.6491191 , 0.14112021, 0.08680065,\n",
       "       0.17800981, 0.98518825, 0.8720975 , 0.83865976, 0.83865976,\n",
       "       0.05561107, 0.1131337 , 0.61621237, 0.05947039, 0.07946019,\n",
       "       0.17254312, 0.986434  , 0.61118364, 0.83834136, 0.98841304,\n",
       "       0.8246706 , 0.06150243, 0.06773431, 0.24094951, 0.12111206,\n",
       "       0.9891345 , 0.50239813, 0.06809592, 0.13638236, 0.06745363,\n",
       "       0.99600184, 0.64603406, 0.17416905, 0.9872686 , 0.04605198,\n",
       "       0.11313321, 0.00747689, 0.8720975 , 0.03975321, 0.94318736,\n",
       "       0.13402113, 0.06747481, 0.04022051, 0.9920936 , 0.82675564,\n",
       "       0.06747481, 0.33092654, 0.06280035, 0.09402158, 0.9637786 ,\n",
       "       0.06012549, 0.14089689, 0.3125505 , 0.09924887, 0.5095116 ,\n",
       "       0.06096161, 0.05999392, 0.92453945, 0.06745363, 0.11758777,\n",
       "       0.04605198, 0.0396034 , 0.99198514, 0.07665209, 0.06012549,\n",
       "       0.37062582, 0.9459999 , 0.96656173, 0.15484886, 0.22639091,\n",
       "       0.08704498, 0.05807406, 0.17404819, 0.26933444, 0.12415101,\n",
       "       0.04560379, 0.95283043, 0.93398166, 0.03975681, 0.17447144,\n",
       "       0.53912616, 0.45829543, 0.8901389 , 0.04551754, 0.28953192,\n",
       "       0.73984313, 0.33701578, 0.8836237 , 0.03780229, 0.15130086,\n",
       "       0.9386749 , 0.06912817, 0.13740422, 0.9640393 , 0.04620329,\n",
       "       0.9198796 , 0.9782036 , 0.2538313 , 0.8896903 , 0.25378776,\n",
       "       0.14408521, 0.06037207, 0.14406337, 0.40916172, 0.0461596 ,\n",
       "       0.20800014, 0.2538313 , 0.97121036, 0.86540353, 0.03975681,\n",
       "       0.2538313 , 0.0602196 , 0.25347102, 0.05715452, 0.0461596 ,\n",
       "       0.05947039, 0.07665209, 0.2538313 , 0.03975248, 0.8896903 ,\n",
       "       0.04560379, 0.06068285, 0.9089248 , 0.8589129 , 0.51551867,\n",
       "       0.2343989 , 0.06096161, 0.08720516, 0.0671951 , 0.607389  ,\n",
       "       0.00747689, 0.07665209, 0.0602196 , 0.16859917, 0.65726006,\n",
       "       0.11758777, 0.9911326 , 0.19747655, 0.17447144, 0.7920437 ,\n",
       "       0.06037207, 0.06692073, 0.25378776, 0.20943835, 0.06773431,\n",
       "       0.08946828, 0.9872331 , 0.05202322, 0.96260166, 0.14073677,\n",
       "       0.04658949, 0.4158461 , 0.8380431 , 0.16859917, 0.9774817 ,\n",
       "       0.21936184, 0.92883915, 0.2510079 , 0.19512902, 0.1698068 ,\n",
       "       0.16926402, 0.0461596 , 0.25383422, 0.98062897, 0.14054805,\n",
       "       0.25374892, 0.86540353, 0.04581727, 0.8901389 , 0.17409845,\n",
       "       0.9942784 , 0.06757682, 0.08680065, 0.97696143, 0.08680216,\n",
       "       0.05761185, 0.86540353, 0.10893155, 0.06012549, 0.10859369,\n",
       "       0.97180927, 0.08680216, 0.6491191 , 0.6159649 , 0.3347696 ,\n",
       "       0.93844855, 0.2538313 , 0.99175787, 0.05145799, 0.98286384,\n",
       "       0.960636  , 0.08463882, 0.08463882, 0.14472537, 0.3766736 ,\n",
       "       0.25383747, 0.9462282 , 0.2539291 , 0.089031  , 0.9476015 ,\n",
       "       0.94469035, 0.10453386, 0.03977047, 0.14028943, 0.5050423 ,\n",
       "       0.2538313 , 0.96673363, 0.13939321, 0.9756751 , 0.14065152,\n",
       "       0.03975681, 0.06010351, 0.15557672, 0.0461596 , 0.37062582,\n",
       "       0.11454508, 0.06757682, 0.09156284, 0.08680216, 0.17399792,\n",
       "       0.05598091, 0.98319477, 0.2538331 , 0.83834136, 0.0461596 ,\n",
       "       0.07367381, 0.8720975 , 0.9877045 , 0.4930709 , 0.17416905,\n",
       "       0.8835632 , 0.9891901 , 0.06280035, 0.21110089, 0.08734329,\n",
       "       0.97908604, 0.05811002, 0.4385697 , 0.06773431, 0.0461596 ,\n",
       "       0.05952628, 0.9872331 , 0.05961954, 0.25815523, 0.06475088,\n",
       "       0.09180216, 0.97889555, 0.0542559 , 0.08680065, 0.36112618,\n",
       "       0.7919454 , 0.04605198, 0.23922138, 0.0602196 , 0.19191475,\n",
       "       0.05666218, 0.17409845, 0.7831022 , 0.94431096, 0.99538684,\n",
       "       0.06439568, 0.04546585, 0.89520925, 0.03975681, 0.0602196 ,\n",
       "       0.94319504, 0.08458671, 0.58716595, 0.95469797, 0.09402158,\n",
       "       0.22417943, 0.28491834, 0.30378765, 0.06753437, 0.0751856 ,\n",
       "       0.25376773, 0.04215306, 0.99006206, 0.14079978, 0.03975393,\n",
       "       0.2537932 , 0.05947352, 0.14337398, 0.15361188, 0.14780575,\n",
       "       0.9640393 , 0.17416905, 0.22061239, 0.05080682, 0.05599888,\n",
       "       0.06753437, 0.98841304, 0.14780575, 0.11405413, 0.8896903 ,\n",
       "       0.39686075, 0.06757682, 0.2076649 , 0.04581146, 0.42126828,\n",
       "       0.04605198, 0.9571087 , 0.06812738, 0.8385366 , 0.4086549 ,\n",
       "       0.10526569, 0.04605198, 0.22656426, 0.09551204, 0.15568815,\n",
       "       0.65944463, 0.09828454, 0.25384203, 0.0598033 , 0.06294975,\n",
       "       0.09681793, 0.09551204, 0.04596781, 0.0602196 , 0.9712321 ,\n",
       "       0.9525913 , 0.16251747, 0.05598091, 0.15484886, 0.07665209,\n",
       "       0.06745363, 0.14089689, 0.5155413 , 0.03390043, 0.92516696,\n",
       "       0.83929485, 0.5968107 , 0.06888585, 0.00747689, 0.13237277,\n",
       "       0.17904185, 0.01839225, 0.06972259, 0.06747481, 0.98783803,\n",
       "       0.151874  , 0.76191247, 0.11405413, 0.18009059, 0.2538313 ,\n",
       "       0.057392  , 0.0602196 , 0.8383001 , 0.2542382 , 0.05991887,\n",
       "       0.9964122 , 0.25383422, 0.7313816 , 0.10061001, 0.13743918,\n",
       "       0.06280035, 0.87333053, 0.25383422, 0.9962247 , 0.67305267,\n",
       "       0.98457336, 0.2510079 , 0.28420934, 0.17796877, 0.05715452,\n",
       "       0.0673264 , 0.99600184, 0.80823064, 0.04194856, 0.06001269,\n",
       "       0.9790021 , 0.04775736, 0.05715452, 0.05715452, 0.8159975 ,\n",
       "       0.06836342, 0.730278  , 0.8383105 , 0.10361991, 0.58461106,\n",
       "       0.9960315 , 0.09217218, 0.07665209, 0.09551204, 0.09551204,\n",
       "       0.18825218, 0.11113   , 0.97800916, 0.04605198, 0.04605198,\n",
       "       0.25627646, 0.3441683 , 0.98932236, 0.14059752, 0.17416905,\n",
       "       0.29432496, 0.7955698 , 0.9640393 , 0.2538469 , 0.16926402,\n",
       "       0.97070664, 0.6498854 , 0.06132169, 0.14079978, 0.93584967,\n",
       "       0.9189398 , 0.1738569 , 0.06793886, 0.0602196 , 0.9904922 ,\n",
       "       0.05145799, 0.05952628, 0.1402946 , 0.9435794 , 0.04596781,\n",
       "       0.9899165 , 0.11361231, 0.22368003, 0.0865883 , 0.17522931,\n",
       "       0.14181298, 0.06007222, 0.86540353, 0.08680065, 0.7951269 ,\n",
       "       0.06742815, 0.03975681, 0.393855  , 0.03975465, 0.9966976 ,\n",
       "       0.61118364, 0.97263455, 0.5204942 , 0.7696982 , 0.14026795,\n",
       "       0.14039357, 0.5036362 , 0.02858267, 0.781712  , 0.19348067,\n",
       "       0.03975681, 0.11802173, 0.0047003 , 0.12192321, 0.14079978,\n",
       "       0.05715452, 0.9701443 , 0.33486885, 0.20809646, 0.29554498,\n",
       "       0.05715452, 0.94845074, 0.78622687, 0.63319564, 0.14022091,\n",
       "       0.17380665, 0.18719801, 0.5050423 , 0.05715452, 0.9874074 ,\n",
       "       0.14079453, 0.07259628, 0.05598091, 0.08463882, 0.17447144,\n",
       "       0.15361188, 0.42210528, 0.1547253 , 0.05902503, 0.07966739,\n",
       "       0.9792326 , 0.14128326, 0.18719801, 0.71961236, 0.01839225,\n",
       "       0.03961917, 0.11405413, 0.9354738 , 0.03975681, 0.9959955 ,\n",
       "       0.49302778, 0.92453945, 0.08680216, 0.14077356, 0.06799044,\n",
       "       0.9820415 , 0.06836342, 0.0461596 , 0.22775619, 0.12305316,\n",
       "       0.0676066 , 0.0899969 , 0.97825503, 0.09755953, 0.04658949,\n",
       "       0.05984391, 0.00124422, 0.09890594, 0.20571648, 0.9904919 ,\n",
       "       0.01775489, 0.06001269, 0.8442625 , 0.9688769 , 0.8901389 ,\n",
       "       0.69636023, 0.9911335 , 0.2538313 , 0.8246001 , 0.08680216,\n",
       "       0.04494499, 0.07581635, 0.9701443 , 0.0047003 , 0.09551204,\n",
       "       0.8720975 , 0.9097231 , 0.34998083, 0.04718346, 0.7772251 ,\n",
       "       0.14079978, 0.9694622 , 0.20195459, 0.06093955, 0.93341434,\n",
       "       0.6111609 , 0.06943402, 0.06757682, 0.04605198, 0.986163  ,\n",
       "       0.9453853 , 0.06010351, 0.519191  , 0.15130086, 0.14026795,\n",
       "       0.05485353, 0.09551204, 0.9795868 , 0.1592902 , 0.76310796,\n",
       "       0.16926402], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_reshape = np.reshape(a=predictions, newshape=len(predictions))\n",
    "predictions_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_round = np.where(predictions_reshape > 0.5, 1, 0)\n",
    "predictions_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0              1         0\n",
       "1              2         1\n",
       "2              3         0\n",
       "3              4         1\n",
       "4              5         0\n",
       "..           ...       ...\n",
       "886          887         0\n",
       "887          888         1\n",
       "888          889         0\n",
       "889          890         1\n",
       "890          891         0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_by_pid = pd.DataFrame(\n",
    "    data={\"PassengerId\": passanger_id, \"Survived\": predictions_round}\n",
    ")\n",
    "\n",
    "predictions_by_pid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-ml-tfpj-M2nteehU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
